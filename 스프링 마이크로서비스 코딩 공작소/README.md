# 1장. 스프링, 클라우드와 만나다

## 1.1 마이크로서비스란?

마이크로서비스 개념이 발전하기 전, 대부분의 웹 기반 어플리케이션은 모놀리식 아키텍처 형태로 개발되었다.
모놀리식 아키텍처에서 애플리케이션은 배포 가능한 단일 소프트웨어 산출물로 전달된다.

일반적으로 개발 팀은 애플리케이션의 개별 기능을 담당하는데, 모놀리식 애플리케이션이 크고 복잡해지면
애플리케이션을 담당하는 각 팀의 의사 소통과 조정 비용이 증가한다.
모놀리식 애플리케이션은 각 팀에서 변경이 있을 때마다 애플리케이션 전체를 다시 빌드하고 테스트해서 배포해야 한다.

마이크로서비스는 느슨히 결합된 작은 분산 서비스다.
마이크로서비스를 사용하면 대형 애플리케이션을 관리하기 쉽고, 제한된 책임을 담당하는 컴포넌트로 분해할 수 있다
마이크로서비스는 코드 베이스를 명확히 정의한 작은 조각으로 분리해서 대형 코드 베이스에서 발생하는
전통적인 복잡성 문제를 해결한다.
마이크로서비스를 고려할 때 수용해야 할 핵심 개념은 애플리케이션 기능을 분해하고 분리해서
완전히 상호 독립적이어야 한다는 것이다.

마이크로 서비스는 코드와 소스 관리 저장소, 인프라가 이제 애플리케이션의 다른 부분과 완전히 독립적이기에
각 팀은 독립적으로 빌드와 테스트, 배포를 할 수 있다.

**마이크로 서비스 아키텍처의 특징**

- 애플리케이션 로직을 각자 책임이 명확한 작은 컴포넌트들로 분해하고 이들을 조합해서 솔루션을 제공한다.

- 각 컴포넌트는 작은 책임 영역을 담당하고 완전히 상호 독립적으로 배포된다.
  마이크로서비스는 비즈니스 영역의 한 부분에서만 책임을 담당한다.
  그리고 여러 애플리케이션에서 재사용할 수 있어야 한다.

- 마이크로서비스는 몇 가지 기본 원칙(표준이 아닌 원칙임에 유의)에 기반을 두며
   서비스 소비자와 서비스 제공자 사이의 데이터 교환을 위해 HTTP와 JSON같은 경량 통신 프로토콜을 사용한다.

- 애플리케이션은 항상 기술 중립적 프로토콜(JSON이 가장 보편적이다)을 사용해 통신하므로
  서비스 구현 기술과는 무관하다.
  따라서 마이크로서비스 기반으니 애플리케이션을 다양한 언어와 기술로 구축할 수 있다는 것을 의미한다.

- 작고 독립적이며 분산된 마이크로서비스를 사용해 조직은 명확히 정의된 책임 영역을 담당하는 소규모 팀을 보유할 수 있다.
  이 팀들은 애플리케이션 출시 처럼 하나의 목표를 향해 일하지만, 자기가 개발하는 서비스만 책임진다.

  

## 1.2 스프링은 무엇이고 마이크로서비스와 어떤 관련이 있을까?

스프링은 자바 기반 애플리케이션을 구축하는 사실상 표준 개발 프레임워크다.
의존성 주입이라는 핵심 개념에 기반을 두고 있어, 관례와 애너테이션으로 객체 간 관계를 외부화 할 수 있어
대규모 자바 프로젝트를 더 쉽게 관리할 수 있다.

스프링 부트는 스프링 프레임워크를 재구성한 것이다. 핵심 기능은 수용하지만 많은 ‘엔터프라이즈’ 기능을 제거하고
자바 기반의 REST 지향 마이크로서비스 프레임워크를 제공한다.
단순한 애너테이션으로 자바 개발자는 외부 애플리케이션 컨테이너 없이도 패키지하고 배포할 수 있는
REST 마이크로서비스를 신속하게 구축할 수 있다.

스프링 클라우드 프레임워크를 사용하면 사설 및 공용 클라우드에 마이크로서비스를 쉽게 운영하고 배포할 수 있다.
스프링 클라우드는 널리 사용되는 클라우드 관리용 마이크로서비스 프레임워크를 공통 프레임워크에 포함하고,
코드에서 애노테이션을 다는 것처럼 이러한 기술을 쉽게 사용하고 배포할 수 있게 한다.



## 1.6 애플리케이션 구축 방식을 바꾸는 이유

글로벌 경쟁이 치열해지며 이러한 경쟁 압박은 개발자가 애플리케이션 구축을 바라보는 방식이 다음 현상에 영향을 받고있다.

- **복잡성이 증가했다**

  고객은 조직의 모든 부분이 자신을 인식하길 기대한다.
  단 하나의 데이터베이스와 통신하고 다른 애플리케이션과 통합되지 않은 ‘단절된’ 애플리케이션은 더 이상 표준이 아니다.
  오늘날 애플리케이션은 회사 데이터센터 내부의 여러 서비스와 데이터베이스 뿐만 아니라
  인터넷으로 외부 서비스 제공자와도 통신해야 한다.

- **고객은 더 빠른 출시를 원한다**

  고객은 더 이상 소프트웨어 패키지를 연 단위로 릴리스하거나 버전을 올리길 기대하지 않는다.
  그 대신 소프트웨어 제품 기능이 따로 번들링이되어 전체 제품의 릴리스를 기다리지 않고 새로운 기능이
  몇 주나 며칠 안에 재빨리 릴리스되길 기대한다.

- **성능 및 확장성**

  글로벌 애플리케이션에서는 애플리케이션이 처리해야 할 트랜잭션 양고 유입될 시점을 매우 예측하기 어렵다.
  애플리케이션은 여러 서버로 신속히 확장한 후 확장이 필요 없다면 다시 축소해야한다.

- **고객은 애플리케이션을 항상 사용할 수 있길 기대한다**

  고객은 한 번의 클릭만으로 경쟁사로 이탈 할 수 있으므로, 회사의 애플리케이션은 회복성이 높아야 한다.
  애플리케이션의 한 부분에서 에러나 문제가 있어도 애플리케이션 전체가 다운되어서는 안 된다.

이러한 기대 사항을 충족하려면 개발자는 확장성과 중복성이 높은 애플리케이션을 구축하기 위해
독립적으로 빌드하고 배포할 수 있는 작은 서비스로 애플리케이션을 분리해야 한다는 역설을 수용해야 한다.
애플리케이션을 작은 서비스로 떼어 내서 단일한 모놀리식 산출물에서 벗어난다면 우리는 다음 특징이 있는 시스템을 구축할 수 있다.

- **유연성**

  새로운 기능을 신속하게 제공하도록 분리된 서비스를 구성하고 재배치할 수 있다.
  다른 것과 동작하는 코드 단위가 작을수록 코드 변경에 따른 복잡성을 낮추고 코드 배포를 테스트하는 시간도 줄어든다.

- **회복성**

  분리된 서비스란 더 이상 애플리케이션 한 부분의 저하로 전체가 망가지는 진흙덩이 애플리케이션이 아니라는 의미다.
  실패는 애플리케이션의 작은 부분에 국한되어 애플리케이션 전체 장애로 확대되기 전에 억제된다.
  또 회복 불능 에러가 발생했을 때도 애플리케이션이 원활하게 기능 저하될 수 있다.

- **확장성**

  분리된 서비스를 여러 서버에 수 평적으로 쉽게 분산할 수 있어 기능 및 서비스를 적절히 확장할 수 있다.
  애플리케이션의 모든 로직이 얽혀 잇는 모놀리식 애플리케이션은 한 부분이 병목점이 되더라도 전체를 확장해야 한다.
  작은 서비스를 확장하는 것은 국지적이며 비용 효율이 더 높다.

**작고 단순하며 분리된 서비스 = 확장 가능하고 회복적이며 유연한 애플리케이션**



## 1.8 왜 클라우드와 마이크로서비스인가?

마이크로서비스 기반 아키텍처의 핵심 개념은 각 서비스를 독립된 개별 산출물로 패키징하고 배포한다는 것이다.
서비스 인스턴스를 신속하게 시작할 수 있고 서비스 인스턴스는 서로 차이가 없어야 한다.

마이크로서비스를 작성하는 개발자는 서비스를 다음 중 어디에 배포할지 조만간 결정해야 할 것이다.

- **물리적 서버**

  물리적 서버는 용량을 빠르게 늘릴 수 없고 여러 물리적 서버로 마이크로서비스를 수평 확장하는 데 상당한 비용이 든다.

- **가상 머신 이미지**

  마이크로서비스의 주요 이점 중 하나는 확장하고 실패 이벤트를 받을 때 신속하게
  마이크로서비스 인스턴스를 시작하고 종료할 수 있다는 것이다.

  가상 머신은 주요 클라우드 공급자의 마음이자 정신이다.
  마이크로서비스를 가상 머신 이미지에 패키징한 후 서비스의 여러 인스턴스를 신속하게
  IaaS형 사설 및 공용 클라우드에 배포하고 시작할 수 있다.

- **가상 컨테이너**

  가상 컨테이너는 가상 머신 이미지 기반의 마이크로서비스 배포를 자연스럽게 확장한 것이다.
  서비스를 완전히 가상 머신에 배포하는 대신 많은 개발자가 도커 컨테이너로 자기 서비스를 클라우드에 배포한다.
  가상 컨테이너는 가상 머신 안에서 실행된다.
  가상 컨테이너를 사용하면 하나의 가상 머신을 같은 가상 머신 이미지를 공유하는 완전 자립형 프로세스로 분리할 수 있다.

클라우드에 기반을 둔 마이크로서비스의 장점은 탄력성 개념을 중심으로 한다.
클라우드 서비스 공급자를 통해 몇 분 안에 새로운 가상 머신과 컨테이너를 빠르게 가동시킬 수 있다.
서비스 용량이 감소한다면 추가 비용을 들이지 않고도 가상 서버를 줄일 수 있다.
클라우드 공급자를 사용해 마이크로서비스를 배포하면 애플리케이션을 위해 훨씬 더 높은 수준의 수평 확장성을 얻는다.
서버 탄력성은 애플리케이션 또한 회복력이 높다는 것을 의미한다.
마이크로서비스 중 하나에 문제가 발생해서 고장 나더라도 새로운 서비스 인스턴스를 가동해
개발 팀이 문제를 해결할 수 있을 만큼 오랜 기간 애플리케이션을 정상으로 유지할 수 있다.

책에서는 모든 마이크로서비스와 관련 인프라스트럭처를 도커 컨테이너를 사용해 IaaS 기반클라우드 공급자에게 배포할 것이다.
이 방식은 마이크로서비스에서 사용되는 일반적인 배포 토폴로지다.

- **간소화된 인프라스트럭처 관리**

  IaaS 클라우드 공급자는 서비스를 최대한 통제할 수 잇는 역량을 제공한다.
  간단한 API 호출로 새로운 서비스를 시작하고 정지할 수 있다.

- **엄청난 수평 확장성**

  IaaS 클라우드 공급자를 사용하면 하나 이상의 서비스 인스턴스를 신속하고 간결하게 시작할 수 있다.
  이 기능을 이용해 서비스를 재빨리 확장하고 오작동하거나 고장 난 서버를 우회할 수 있다.

- **지리적 분산을 이용한 높은 중복성**

  IaaS 공급자는 필요에 따라 다수의 데이터센터를 보유한다.
  IaaS 클라우드 공급자가 마이크로서비스를 배포함녀 데이터센터의 클러스터보다 더 높은 수준의 중복성을 얻을 수 있다.

  

## 1.9 마이크로서비스는 코드 작성 이상을 의미

개별 마이크로서비스 구축에 관련된 개념은 이해하기 쉽지만 견고한 마이크로서비스 애플리케이션을 실행하고 지원하는 것은
서비스 코드를 작성하는 것 이상이 필요하다.

- **적정 크기**

  마이크로서비스가 과도한 책임을 맡지 않도록 어떻게 적절한 크기로 만들 수 있을까?
  서비스가 적절한 크기가 되면 애플리케이션을 신속히 변경하고 전체 애플리케이션의 전반적인 장애를 줄일 수 있다는 것을 기억하자.

- **위치 투명성**

  마이크로서비스 애플리케이션에서 서비스의 다수 인스턴스가 재빨리 시작하고 종료될 때
  서비스 호출에 대한 물리적 상세 정보를 관리할 수 있는 방법은 무엇인가?

- **회복성**

  장애가 발생한 서비스를 우회하고 “빨리 실패”하는 방법을 사용해 어떻게 마이크로서비스 소비자를 보호하고
  애플리케이션의 전반적 무결성을 유지할 것인가?

- **반복성**

  새로운 서비스 인스턴스가 시작할 때마다 운영 환경의 다른 서비스 인스턴스 구성과 코드 베이스를
  동일하게 만드는 방법은 무엇인가?

- **확장성**

  비동기 프로세싱과 이벤트를 사용해 서비스 간 의존성을 최소화하고 마이크로서비스를 원만하게 확장할 수 잇는 방법은 무엇인가?

책에서는 이러한 질문에 답하기 위해 패턴 기반의 접근 방법을 사용한다.
패턴에 기반을 둔 방법은 서로 다른 기술 구현 방식에 사용할 수 있는 일반적인 설계를 제시한다.
특히 다음 여섯 가지 마이크로서비스 패턴을 다룰 것이다.

- 핵심 개발 패턴(core development pattern)

- 라우팅 패턴(routing pattern)

- 클라이언트 회복성 패턴(client resilency pattern)

- 보안 패턴(security pattern)

- 로깅 및 추적 패턴(logging and tracing pattern)

- 빌드 및 배포 패턴(build and deployment pattern)

  

### 1.9.1 마이크로서비스 핵심 개발 패턴

- **서비스 세분성**

  비즈니스 영역을 마이크로서비스로 분해해서 각 마이크로서비스가 적정 수준의 책임을 갖게 하는 방법은 무엇인가?
  서비스가 다른 비즈니스 문제 영역과 책임이 겹치도록 너무 굵게 나뉘면 시간이 지나면서 유지 보수와 변경이 어려워진다.
  서비스가 너무 잘게 나뉘면 애플리케이션의 전반적 복잡성이 증가되고, 서비스는 데이터 저장소에 엑세스하는 것 외에
  아무런 로직도 없는 멍청한 데이터 추상화 계층으로 전락한다

- **통신 프로토콜**

  마이크로서비스와 데이터 교환을 위한 XML 이나 JSON, 아니면 Thrift 같은 바이너리 프로토콜을 사용하는가?
   JSON이 가장 이상적인 이유와 마이크로서비스와 데이터를 교환하는 데 일반적으로 선택되는 이유를 살펴 볼 것이다.

- **인터페이스 설계**

  개발자가 서비스 호출에 상요하는 실제 서비스 인터페이스를 설계하는 최선의 방법은 무엇인가?
  서비스 의도를 전달하도록 서비스 URL을 구조화하는 방법은 무엇인가? 서비스 버전 관리는?

- **서비스 간 이벤트 프로세싱**

  서비스 간 하드 코딩된 의존성을 최소화하고 애플리케이션 회복성을 높이기 위해 마이크로서비스를 분리하는 방법은 무엇인가?

  

### 1.9.2 마이크로서비스 라우팅 패턴

마이크로서비스 라우팅 패턴은 마이크로서비스를 사용하려는 클라이언트 애플리케이션 서비스의 위치를 발견하고
라우팅하는 방법을 다룬다.
클라우드 기반 애플리케이션에는 수백 개의 마이크로서비스가 실행 중일 수 있다.
서비스의 물리적 IP 주소를 추상화하고 서비스 호출에 대한 단일 진입점을 만들어야 모든 서비스 호출에 대한
일관적 보안과 콘텐츠 정책을 보장할 수 있다.

서비스 디스커버리와 라우팅은 “서비스에 대한 클라이언트의 요청을 특정 서비스 인스턴스에 어떻게 전달할 수 있을까?" 라는
질문에 대한 답변이다.

- **서비스 디스커버리**

  클라이언트 애플리케이션이 서비스 위치를 하드 코딩하지 않고 찾을 수 있도록
  마이크로서비스를 어떻게 탐색 가능하게 만들 수 있을까?
  오작동하는 마이크로서비스 인스턴스를 가용 서비스 인스턴스 풀에서 어덯게 제거해야 할까?

- **서비스 라우팅**

  보안 정책과 라우팅 규칙을 마이크로서비스 애플리케이션의 여러 서비스와 서비스 인스턴스에 차별 없이 적용하기 위해
  모든 서비스에 대한 단일 진입점을 제공하는 방법은 무엇인가?
  팀의 각 개발자가 서비스에 라우팅을 제공하기 위한 솔루션을 자체적으로 마련할 필요가 없도록 하는 방법은 무엇인가?

서비스 디스커버리와 서비스 라우팅은 서로 종속적이지 않다.



### 1.9.3 마이크로서비스 클라이언트 회복성 패턴

마이크로서비스 아키텍처는 고도로 분산되어 있어서 1개의 서비스 문제가
서비스 소비자에게 연쇄적으로 발생하지 않도록 방지하는 데 매우 민감해져야 한다.

- **클라이언트 측 부하 분산 (client-side load balancing)**

  마이크로서비스의 여러 인스턴스에 대한 호출이 정상 인스턴스에 분산하도록 서비스 인스턴스의 위치를 캐싱하는 방법은 무엇인가?

- **회로 차단기 패턴 (circuit breakers pattern)**

  클라이언트가 고장 나거나 성능 문제가 있는 서비스를 계속 호출하지 않게 하는 방법은 무엇인가?
  서비스가 느리게 실행되면 서비스를 호출하는 클라이언트의 리소스가 소모된다.
  비정상 마이크로서비스 호출이 빨리 실패하면 호출 클라이언트가 신속하게 응답하고 적절한 조치를 취할 수 있다.

- **폴백 패턴 (fallback pattern)**

  서비스 호출이 실패할 때 호출한 마이크로서비스가 아닌 다른 대체 수단을 사용해
  서비스 클라이언트가 작업을 수행할 수 있게 하는 ‘플러그인’ 메커니즘을 어떻게 제공할 것인가?

- **벌크헤드 패턴 (bulkhead pattern)**

  마이크로서비스 애플리케이션은 작업을 수행하기 위해 여러 분산 자원을 사용한다.
  오작동하는 서비스 호출 하나가 나머지 애플리케이션에 부정적인 영향을 미치지 않도록 이러한 호출을 구분하는 방법은 무엇인가?

  

### 1.9.4 마이크로서비스 보안 패턴

- **인증 (authentication)**

  서비스를 호출하는 서비스 클라이언트가 자신이라는 것을 어떻게 알 수 있는가?

- **인가 (authorization)**

  마이크로서비스를 호출하는 서비스 클라이언트가 수행하려는 작업을 수행할 자격이 있는지 어떻게 알 수 있는가?

- **자격 증명 (credential management) 관리와 전파 (propagation)**

  서비스 클라이언트가 한 트랜잭션과 관련된 여러 서비스 호출에서 자격 증명을 항상 제시하지 않아도 될 방법은 무엇인가?
  특히 OAuth와 자바스크립트 웹 토큰 (JWT, Javascript Web Token) 같은 토큰 기반 보안 표준을 사용해
  토큰 (서비스 호출 간에 전달해 사용자를 인증하고 인가할 수 있는 토큰)을 얻는 방법을 살펴볼 것이다.

  

### 1.9.5 마이크로서비스 로깅 및 추적 패턴

마이크로서비스 아키텍처의 장점은 모놀리식 애플리케이션이 작은 기능 단위로 분해되어 독립적으로 배포된다는 것이다.
마이크로서비스의 단점은 애플리케이션과 서비스 안에서 어떤 일이 일어나고 있는지 디버깅과 추적이 훨씬 더 어렵다는 것이다.

- **로그 상관관계 (log correlation)**

  단일 트랜잭션에 대해 여러 서비스 간 생성된 모든 로그를 함께 연결하는 방법은 무엇인가?
  이 패턴을 이용해 상관관계 ID를 구현하는 방법을 살펴볼 것이다.
  이 ID는 한 트랜잭션에서 발생하는 모든 서비스 호출 사이에 전달되는 고유 식별자이며
  각 서비스에서 출력하는 로그 항목을 함께 묶는 데 사용된다.

- **로그 수집 (log aggregation)**

  이 패턴으로 서비스 (개별 인스턴스)에서 생성된 모든 로그를 질의 (query) 가능한
  단일 데이터베이스로 취합하는 방법을 살펴볼 것이다.
  그리고 상관관계 ID로 수집된 로그 검색을 지원하는 방법도 살펴볼 것이다.

- **마이크로서비스 추적 (microservice tracing)**

  끝으로 트랜잭션과 연관된 모든 서비스에서 클라이언트 트랜잭션 흐름을 시각화 하고
  트랜잭션과 관련된 서비스의 성능 특성을 이해하는 방법을 살펴볼 것이다.

  

### 1.9.6 마이크로서비스 빌드 및 배포 패턴

마이크로서비스 아키텍처의 핵심 부분 중 하나는 마이크로서비스의 각 인스턴스가 모두 동일해야 한다는 것이다.
서버가 배포된 이후의 변경 때문에 발생하는 ‘구성 편차 (configuration drift)’는 애플리케이션 안정성을 해치므로 허용될 수 없다.

```
너무 자주 듣는 말

필자는 작고 제한된 범위의 마이크로서비스가 '불변 인프라스트럭처'라는 개념을
도입할 절호의 기회를 가져다 준다는 것을 깨달았다.
이 개념은 서비스가 배포되고 나면 서비스가 실행 중인 인프라스트럭처를 절대로
사람이 직접 건드려서는 안 된다는 것이다.
운영 환경에서 시작하는 특정 마이크로서비스의 모든 인스턴스 사이에 동일성을
보장해야 하기 때문에 불변 인프라스트럭처는 마이크로서비스 아키텍처를 성공으로
이끄는 매우 중요한 요소다.
```

- **빌드 및 배포 파이프라인**

  조직의 모든 환경에서 원클릭 빌드와 배포를 강조하는 반복 가능한 빌드 및 배포 프로세스를 어떻게 만드는가?

- **코드형 인프라스트럭처 (infrastructure as code)**

  소스 제어를 사용해 실행하고 관리할 수 있는 코드로 서비스 프로비저닝을 처리하는 방법은 무엇인가?

- **불변 서버 (immutable servers)**

  마이크로서비스 이미지를 생성하고 배포한 후 변경하지 못하게 하려면 어떻게 해야 하는가?

- **피닉스 서버 (phoenix servers)**

  서버가 오래 실행될수록 구성 편차가 발생할 가능성도 높아진다.
  마이크로서비스를 실행하는 서버를 정기적으로 해체(종료)하고 불변 이미지를 재생성하려면 어떻게 해야 하는가?

이러한 패턴 및 주제와 함께 우리 목표는 스테이지 도는 운영 환경처럼 상위 환경에 도달하기 전에
최대한 빨리 구성 편차를 과감하게 노출하고 근절하는 것이다.



## 1.10 스프링 클라우드로 마이크로서비스 구축

## 1.10.1 스프링 부트

스프링 부트는 마이크로서비스 구현에 필요한 핵심 기술이다.
스프링 부트로 REST 기반 마이크로서비스를 구축하는 주요 작업을 단순화해 마이크로서비스를 상당히 쉽게 개발할 수 있다.
스프링 부트에서는 HTTP 형식의 동사를 URL에 매핑하고 JSON 프로토콜을 자바 객체로 직렬화할 뿐만 아니라
자바 예외를 표준 HTTP 에러 코드에 매핑하는 작업도 아주 간편해졌다.



### 1.10.2 스프링 클라우드 컨피그

스프링 클라우드 컨피그(Config)는 중앙 집중식 서비스로 애플리케이션 구성 데이터 관리를 담당하고
애플리케이션 데이터(특히 환경별 구성 데이터)를 마이크로서비스와 완전히 분리한다.
따라서 마이크로서비스 인스턴스가 아무리 많더라도 항상 동일한 구성을 유지할 수 있다.
스프링 클라우드 컨피그에는 고유한 관리 저장소가 있지만 다음 오픈 소스 프로젝트와도 통합된다.

- **깃 (Git)**

  스프링 클라우드 컨피그는 깃 기반 저장소와 통합되어 애플리케이션의 구성 데이터를 저장소에서 읽어 올 수 있다.

- **콘설 (Consul)**

  서비스 인스턴스를 서비스에 등록할 수 있는 오픈 소스 서비스 디스커버리 도구다.
  서비스 클라이언트는 콘설에 서비스 위치를 물어볼 수 있다.
  콘설에는 스프링 클라우드 컨피그가 애플리케이션 구성 데이터를 저장하는 데 사용하는 키-값 저장소 기반 데이터베이스도 있다.

- **유레카 (Eureka)**

  콘설과 유사한 서비스 디스커버리 기능을 제공하는 넷플릭스의 오픈 소스 프로젝트다.
  유레카에도 스프링 클라우드 컨피그와 함께 사용될 수 있는 키-값 데이터베이스가 있다.

  

### 1.10.3 스프링 클라우드 서비스 디스커버리

스프링 클라우드의 서비스 디스커버리를 사용하면 서비스를 사용하는 클라이언트에 서버가 배포된
물리적 위치 (IP 주소나 서버 이름)를 추상화할 수 있다.
서비스 소비자는 물리적 위치보다 논리적 이름을 사용해 서버의 비즈니스 로직을 호출한다.
스프링 클라우드의 서비스 디스커버리는 서비스 인스턴스가 시작하고 종료할 때 등록과 말소를 처리하며,
서비스 디스커버리 엔진의 구현을 위해 콘설과 유레카를 사용할 수 있다.



### 1.10.4 스프링 클라우드/넷플릭스 히스트릭스와 리본

스프링 클라우드는 넷플릭스 오픈 소스 프로젝트와 긴밀하게 통합되었다.
마이크로서비스 클라이언트의 회복성 패턴을 위해 스프링 클라우드는 넷플릭스 히스트릭스 라이브러리와
리본 프로젝트를 포함해서 마이크로서비스 안에서 이 프로젝트를 사용하는 일을 간단하게 만들었다.

넷플릭스 리본 프로젝트는 유레카 같은 서비스 디스커버리 에이전트를 단순하게 통합할 뿐만 아니라
서비스 소비자가 서비스 호출에 대한 클라이언트 측 부하 분산 기능도 제공한다.
이러한 기능을 이용해 서비스 디스커버리 에이전트가 일시적으로 가용하지 않을 때도 클라이언트가 계속 서비스를 호출할 수 있다.



### 1.10.5 스프링 클라우드/넷플릭스 주울

스프링 클라우드는 넷플릭스 주울(Zuul)를 사용해 마이크로서비스 애플리케이션을 위한 서비스 라우팅 기능을 제공한다.
주울은 서비스 요청을 대리 (proxy) 해서 마이크로서비스에 대한 모든 호출이 ‘현관문’처럼
한곳을 통해 대상 서비스에 도달하게하는 서비스 게이트웨이다.
이렇게 서비스 호출을 집중화하면 보안 인가 및 인증, 콘텐츠 필터링, 라우팅 규칙 등 표준 서비스 정책을 시행할 수 있다.



### 1.10.6 스프링 클라우드 스트림

스프링 클라우드 스트림은 마이크로서비스에 경량 메시지 프로세싱을 쉽게 통합할 수 있는 기술이다.
스프링 클라우드 스트림을 이용하면 애플리케이션에서 발생되는 비동기 이벤트를 사용하는 영리한 마이크로서비스를 구축할 수 있고 RabbitMQ와 카프가 같은 메시지 브로커와도 신속하게 통합할 수 있다.



### 1.10.7 스프링 클라우드 슬루스

스프링 클라우드 슬루스는 애플리케이션 안에서 사용되는 HTTP 호출과 메시지 채널(RabbitMQ, Kafaka)에
고유 추적 식별자를 통합할 수 있다.
이러한 추적 번호를 상관관계 ID 또는 추적 ID 라고 하며 애플리케이션에서 여러 서비스를 순회하는 트랜잭션을 추적할 수 있다.
이러한 추적 ID는 마이크로서비스에서 생성하는 모든 로그에 자동으로 추가된다.

스프링 클라우드 슬루스는 페이퍼트레일 같은 로그 수집용 기술 도구 및 집킨 같은 추적 도구와 결합될 때 더 큰 빛을 발한다.
페이퍼트레일은 여러 마이크로서비스의 로그를 실시간으로 질의 가능한 데이터베이스로 수집하는 클라우드 기반 로깅 플랫폼이다.
오픈집킨은 스프링 클라우드 슬루스가 생성한 데이터를 사용해 단일 트랜잭션에 연관된 서비스의 호출 흐름을 시각화 할 수 있다.



### 1.10.8 스프링 클라우드 시큐리티

스프링 클라우드 시큐리티는 서비스에 액세스에 할 수 있는 사람과 어떤 일을 할 수 있는지 통제할 수 있는 인증 및 인가 프레임워크다.
스프링 클라우드 시큐리티는 토큰에 기반을 두며 인증 서버가 발생한 토큰으로 서비스는 서로 통신한다.
호출받는 서비스 모두 HTTP 호출에서 전달된 토큰을 확인해 사용자 신원과 서비스 접근 권한을 검증한다.

게다가 스프링 클라우드 시큐리티는 자바스크립트 웹 토큰을 지원한다. JWT는 OAuth2 토큰의 생성 방식과 생성된
토큰의 디지털 서명에 대한 표준을 제공한다.



### 1.10.9 프로비저닝

프로비저닝 (provisioning)을 구현하기 위해서는 스프링 말고 다른 기술을 사용해야 한다.
스프링 프레임워크는 애플리케이션 개발에 맞추어져 있고 스프링 클라우드처럼 ‘빌드와 배포’ 파이프라인을 생성할 수 있는 도구가 없다. ‘빌드와 배포’ 파이프라인을 구현하기 위해 두 가지 도구, 즉 빌드 도구용 Travis와 마이크로서비스가 포함된
최종 서버 이미지를 만들기 위해 도커를 사용할 것이다.



## 1.11 예제로 배우는 스프링 클라우드

`@EnableCircuitBreaker`  애너테이션은 스프링 마이크로서비스에 이 애플리케이션에서
넷플릭스 히스트릭스 라이브러리가 사용된다고 알려 준다.
`@EnableEurekaClient` 애너테이션은 마이크로서비스 자신을 유레카 서비스 디스커버리 에이전트에 등록하고
서비스 디스커버리를 사용해 코드에서 원격 REST 서비스의 엔드포인트를 검색할 것을 지정한다.
이 서비스의 구성 (configuration)은 접속할 유레카의 위치와 포인트 번호를 지정하는 프로퍼티 파일에 있다는 것을 주목한다.

`@HystrixCommand` 애너테이션은 두가지 작업을 수행한다.

첫 번째 작업은 `helloRemoteServiceCall` 메서드가 호출될 떄 직접 호출되지 않고 히스트릭스가 관리한 스레드 풀에 위임한다.
호출이 너무 오래 걸리면 (기본값 1초) 히스트릭스가 개입하고 호출을 중단시킨다. 이것이 바로 회로 차단기 패턴의 구현이다.

두 번째 작업은 히스트릭스가 관리하는 `helloThreadPool`이라는 스레드 풀을 만드는 것이다.
`helloRemoteServiceCall` 메서드에 대한 모든 호출은 이 스레드 풀에서만 발생하며,
수행 중인 다른 원격 서비스 호출과 격리된다.

끝으로 주목할 것은 `helloRemoteServiceCall`메서드 내부에서 일어나는 일이다.
`@EnableEurekaClient`가 있다면 스프링 부트에 REST 서비스를 호출할 때 수정 `RestTemplate`클래스
(표준 스프링의 RestTemplate 기본 동작 방식과 다르다)를 사용하도록 지정한다.
이 `RestTemplate`클래스로 호출하려는 서비스의 놀리적 서비스 ID를 전달할 수 있다.

```java
ResponseEntity<String> restExchange = restTemplate.exchange
(<http://logical-service-id/name/{firstName}/{lastName}>
```

내부적으로 RestTemplate 클래스는 유레카 서비스에 접속해 1개 이상의`logical-service-id` 서비스 인스턴스에 대한
물리적 위치를 검색한다.
서비스 소비자의 코드는 해당 서비스 위치를 전혀알 필요가 없다.

`RestTemplate` 클래스는 넷플릭스의 리본 라이브러리도 사용한다.
리본은 서비스와 관련된 모든 물리적 엔드포인트 목록을 검색한다. 클라이언트가 서비스를 호출할 때마다
중앙 집중식 부하 분산기를 거치지 않고 모든 서비스 인스턴스를 ‘라운드로빈’ 방식으로 호출한다.
중앙 집중식 로드 밸런서를 제거해 클라이언트 측에 옮김으로써 애플리케이션 이프라스트럭처에서 장애점 (로드 밸런서 고장)
하나를 제거하는 셈이다.

이 시점에서 단지 애너테이션 몇 개로 마이크로서비스에 상당히 많은 기능을 추가한 것에 대해 깊은 인상을 받았으면 좋겠다.
이것이 바로 스프링 클라우드의 강점이다.
개발자는 넷플릭스와 하시코프처럼 최고의 클라우드 기업이 시장에서 단련된 마이크로서비스 기능을 활용할 수 있다.
이러한 기능을 스프링 클라우드 외부에서 사용한다면 설정하는 데 복잡하고 어려울 수 있다.



## 1.13 요약

- 마이크로서비스는 특정 영역을 담당하는 매우 작은 기능 부분이다
- 마이크로서비스를 위한 산업 표준은 없다. 다른 초기 웹 서비스 프로토콜과 달리 마이크로서비스는
  원칙 기반의 접근 방식을 취하고 REST 및 JSON 개념과 연동한다
- 마이크로서비스를 작성하는 것은 쉽지만 완벽하게 운영하려면 사전에 추가적인 고려가 필요하다.
  핵심 개발 패턴과 라우팅, 클라이언트 회복성, 보안, 로깅, 빌드 및 배포 패턴을 포함해
  여러 범주의 마이크로서비스 개발 패턴을 소개했다.
- 마이크로서비스는 언어에 구애받지 않지만 마이크로서비스 구축에 큰 도움이 되는 스프링 프레임워크인
  스프링 부트와 스프링 클라우드를 소개했다.
- 스프링 부트는 REST 및 JSON 기반 마이크로서비스를 단순화한다.
  몇 개의 애너테이션 만으로 마이크로서비스를 신속하게 구축하게 하는 것이 스프링 부트의 목표다.
- 스프링 클라우드는 넷플릭스나 하시코프 같은 회사의 오픈 소스 기술을 집약했다.
  그들의 기술은 스프링 애너테이션에 포함되어 서비스 설정과 구성을 크게 단순화한다.
- 

# **2장. 스프링 부트로 마이크로서비스 구축**

소프트웨어 개발은 정의와 실행의 선형 과정이 아니라 개발팀이 당면한 문제를 제대로 이해하기까지
고객과 **소통하고 고객에게 배우며 전달하는** 활동을 반복하는 진화과정이다.

Waterfall 개발 방법론을 사용하면 다음같은 단점이 발생한다

- **강한 결합**

  비즈니스 로직 호출은 프로그래밍 언어 수준에서 이뤄진다.
  따라서 애플리케이션 컴포넌트를 조금만 수정해도 그 애플리케이션의 다른 부분을 깨뜨리거나
  새로운 버그를 생산할 가능성이 매우 높다.

- **누설**

  대규모 소프트웨어 애플리케이션의 대부분은 다양한 유형의 데이터를 취급한다.
  전통적인 모델에서 데이터는 같은 데이터 저장소 안에서 같은 데이터 모델을 유지한다.
  데이터 사이에 명확한 경계가 있지만 다른 팀의 데이터에 접근하고 싶은 유혹을 자주 받는다.

  다른 영역의 데이터에 쉽게 접근하게 되면 보이지 않는 의존성이 생겨나고 컴포넌트의 내부 데이터 구조에 대한 세부 구현이
  애플리케이션 전체에 유출될 수 있다.
  데이터베이스 테이블 하나를 조금만 변경해도 애플리케이션 전반에 걸쳐 엄청난 코드 수정과 회귀 테스팅이 필요할 수 있다.

- **모놀리식**

  저통적인 애플리케이션에서 대부분의 컴포넌트는 여러 팀에서 공유되는 단일 코드베이스에 저장하므로 코드를 변경할 때마다
  전체 애플리케이션을 재컴파일 하고, 전체 테스팅 주기를 재수행하며 재배포한다.
  애플리케이션 코드 베이스를 조금만 변경해도 비용이 많이 들며 오랜 시간이 소요된다.

마이크로서비스 기반 아키텍처는 기능을 제공하는 데 다른 접근법을 취한다.

- **제한**

  마이크로서비스는 하나의 책임 집합을 가지며 범위가 좁다.
  마이크로서비스는 ‘애플리케이션이 한 가지 일을 하며, 정말 잘하는 서비스 집합에 불과하다’는 유닉스 철학을 수용한다.

- **느슨한 결합**

  마이크로서비스 기반 애플리케이션은 작은 서비스 집합이며, HTTP 와 REST 처럼 비독점적 호출 프로토콜을 사용하는
  구현 기술에 중립적인 인터페이스로 서로 소통한다.
  서비스에 대한 인터페이스가 변하지 않는한 모놀리식 아키텍처보다 더 자유롭게 수정할 수 있다.

- **추상화**

  마이크로서비스는 자신의 데이터 구조와 데이터 소스를 완전히 소유한다.
  마이크로서비스가 소유한 데이터는 해당 서비스만 수정할 수 있다.
  마이크로서비스의 데이터를 보관하는 데이터베이스에서 해당 서비스만 접근할 수 있도록 통제할 수 있다.

- **독립적**

  마이크로서비스 애플리케이션 안의 모든 마이크로서비스는 서로 독립적으로 컴파일하고 배포할 수 있다.
  이는 상호 의존성이 높은 애플리케이션보다 변경 사항을 훨씬 쉽게 분리하고 테스트할 수 있다는 것을 의미한다.

클라우드 기반을 둔 개발에 왜 이러한 마이크로서비스 아키텍처의 특성들이 중요할까?
클라우드 기반 애플리케이션은 일반적으로 다음 특징이 있다.

- **사용자층이 다양하며 대규모다**

  고객마다 서로 다른 제품 기능을 원하며, 이것을 위해 긴 릴리스 주기를 기다리고 싶어하지 않는다.
  마이크로서비스는 작은 범위를 담당하고 명확히 정의된 인터페이스를 통해 접근하므로 기능을 신속히 제공할 수 있다

- **상당한 작동시간이 요구된다**

  마이크로서비스 자체의 분산적 특성 때문에 마이크로서비스 기반 애플리케이션은 애플리케이션 전체를 중단하지 않고도
  고장과 문제를 더 쉽게 격리할 수 있다.
  이로 인해 전반적인 애플리케이션 작동 중지 시간은 줄어들고 결함 저항력은 높아진다.

- **볼륨이 균일하지 않다**

  기업 데이터센터에서 운용되는 전통적인 애플리케이션은 대개 일정한 사용 패턴을 가지므로 용량 계획은 간단하다.
  하지만 클라우드 기반 애플리케이션 환경에서는 클라우드 기반 애플리케이션에 하늘을 찌르는 엄청난 수요를 불러올 수 있다.

  마이크로서비스는 독립적인 배포가 가능한 작은 컴포넌트로 분리되기 있기 때문에 부하를 받는 컴포넌트를 조명하고
  여러 서버에 수평 확장하기도 훨씬 쉽다.

  

## 2.1 아키텍트의 이야기: 마이크로서비스 아키텍처 설계

아키텍트의 역할은 해결해야 될 문제의 동작 모델을 제공하는 것이다.
또 아키텍트는 애플리케이션 코드가 서로 들어맞도록 코드를 작성하는 개발자를 위한 발판도 제공해야 할 것이다.

마이크로서비스 아키텍처를 구축할 때 프로젝트의 아키텍트는 다음 세 가지 일에 집중한다

1. 비즈니스 문제의 분해

2. 서비스 세분화의 확정

3. 서비스 인터페이스의 정의

   

### 2.1.1 비즈니스 문제의 분해

아키텍트는 데이터 영역이 서로 어울리지 않는다면 마이크로서비스들의 서비스 경계를 나눈다.
예를 들어 아키텍트는 코드가 수행할 비즈니스 흐름을 보고 고객 및 제품 정보가 필요하다는 것을 알 수 있다.
이러한 2개의 개별 데이터 영역이 있다는 것은 여러 마이크로서비스의 출현을 암시한다.
2개의 다른 비즈니스 트랜잭션 부분이 교류하는 방식이 일반적으로 마이크로서비스의 서비스 인터페이스가 된다.

비즈니스 문제를 인식하고 마이크로서비스 후보로 분해하는 데 다음 지침을 사용하길 추천한다.

1. **비즈니스 문제를 기술하고 그 문제를 기술하는 데 사용된 명사에 주목하라**

   문제를 기술하는 데 동일한 명사가 반복해서 사용되면 대개 핵심 비즈니스 영역과 마이크로서비스로 만들 기회가 드러난다.

2. **동사에 주목하라**

   동사는 행위를 부각하고 문제가 되는 영역의 윤곽을 자연스럽게 드러낸다. ”트랜잭션 X는 A와 B에서 데이터를 가져와야 해” 라고
   말한다면 대개 여러 서비스가 엮여 동작 중인 상태다.

3. **데이터 응집성을 찾아라**

   비즈니스 문제를 각 부분으로 분해할 때 서로 연관성이 높은 데이터 부분들을 찾는다.
   **마이크로서비스는 자기 데이터를 완전히 소유해야 한다.**
   따라서 대화 중 갑자기 지금껏 논의했던 내용과 근본적으로 다른 데이터를 읽거나 업데이트한다면
   아마도 또 다른 서비스 후보가 필요할 수 있다.

   

### 2.1.2 서비스 세분화의 확정

데이터 모델을 단수화했다면 이제 애플리케이션이 필요한 마이크로서비스를 정의할 단계다.

분리된 기능을 서로 독립적으로 빌드하고 배포할 수 있는 자체 완비형 유닛을 추출하는 것이다.
서비스가 접근하는 실제 데이터베이스 테이블을 서비스에 따라 정리하고 각 서비스가
특정 도메인의 테이블만 엑세스하게 하는 일도 필요하다.

마이크로서비스 아키텍처를 구축할 때 세분화 문제는 중요하지만 다음 개념을 사용해 올바른 해결책을 구할 수 있다.

1. **큰 마이크로서비스에서 시작해 작게 리팩토링하는 것이 더 낫다**

   의욕이 지나쳐 모든 것을 마이크로서비스로 만들어 버리기 쉽다.
   하지만 문제 영역을 한번에 작은 서비스로 분해하면 마이크로서비스가 그저 단순한 데이터 서비스로 전락하기 때문에
   너무 일찍 복잡함을 겪게 된다.

2. **서비스 간 교류하는 방식에 먼저 집중한다**

   이는 문제 영역에 대한 큰 단위의 인터페이스를 만드는데 도움이 된다.
   큰 것을 작게 리팩토링하는 것이 더 쉽다.

3. **문제 여역에 대한 이해가 깊어짐에 따라 서비스 책임도 계속 변한다**

   새로운 애플리케이션 기능이 요구될 때 종종 마이크로서비스가 책임을 맡는다.
   마이크로서비스는 단일 서비스에서 시작해 여러 서비스로 분화되며 성장하는데
   원래 서비스는 새로운 서비스들을 오케스트레이션하고 애플리케이션의 다른 부분에서 새 서비스들의 기능을 캡슐화 한다.

   

**나쁜 마이크로서비스의 징후**

- **너무 크게 나눠저 있는 경우**

  - **책임이 너무 많은 서비스**

    비즈니스 로직이 흐름이 복잡하며 지나치게 다양한 종류의 비즈니스 규칙을 시행한다

  - **많은 테이블의 데이터를 관리하는 서비스**

    여러 테이블에 데이터를 저장하거나 직속 데이터베이스 외부의 테이블에 액세스 하고 있다면
    서비스가 너무 크다는 것을 암시한다.
    필자는 마이크로서비스가 3~5개 테이블을 소유해야 한다는 지침을 세웠다.
    이보다 더 많다면 서비스가 너무 많은 책임을 담당할 가능성이 높다

  - **과다한 테스트 케이스**

    시간이 지나면서 서비스 크기와 책임이 늘어날 수 있다.
    서비스가 적은 수의 테스트 케이스로 시작해 수백 개의 단위 테스트와 통합 테스트 케이스로 늘어난다면
    리팩토링이 필요할 것이다.

- **너무 작게 나눠저 있는 경우**

  - **한 문제 영역 부분에 속한 마이크로서비스가 토끼처럼 번식한다**

    모든 것이 마이크로서비스로 되면 작업 수행이 필요한 서비스 개수가 엄청나게 증가해서
    서비스에서 비즈니스 로직을 만드는 것이 복잡하고 어려워진다.
    애플리케이션에 수십 개의 마이크로서비스가 있고 각 서비스가 하나의 데이터베이스 테이블과 통신할 때 악취가 나곤 한다.

  - **마이크로서비스가 지나치게 상호 의존적이다**

    문제 영역의 한 부분에 있는 마이크로서비스는 하나의 사용자 요청을 완료하기 위해 각 서비스가 서로 계속 호출한다.

  - **마이크로서비스가 단순한 CRUD 집합이 된다.**

    마이크로서비스는 비즈니스 로직의 표현이지 데이터 소스의 추상화 계층이 아니다.
    마이크로서비스가 CRUD 관련 로직만 수행한다면 너무 잘게 나뉘어 있다는 의미다.

마이크로서비스 아키텍처는 처음부터 올바르게 설계하기가 어렵기 때문에 진화론적 사고 과정으로 개발해야 한다.
이것이 잘게 나뉜 서비스보다 굵게 나뉜 서비스에서 시작하는 것이 더 좋은 이유다.
분리된 두 서비스 사이에 너무 많은 호출이 발생하므로 데이터를 합치는 집합(Aggregation) 서비스를 별도로 만들거나
서비스 영역의 명확한 경계선이 없는 서비스에서 물리적 제약이 발생할 수 있다.

완벽한 설계를 위해 시간을 낭비하고 노력에 비해 보여줄 것이 없는 것 보다는 실용적 접근 방식을 취하고 결과물을 전달하자



### 2.1.3 서비스 사이의 대화: 서비스 인터페이스

아키텍트가 제공할 마지막 부분은 애플리케이션의 마이크로서비스가 대화하는 방식을 정의하는 것이다.
마이크로서비스를 사용해 비즈니스 로직을 만든다면 서비스 인터페이스는 직관적이고,
개발자가 1~2개의 애플리케이션 서비스를 학습하고 나면 애플리케이션의 모든 서비스에 대한 동작 규칙을 습득할 수 있어야 한다.

일반적으로 서비스 인터페이스 설계를 고려할 때 다음 지침을 사용할 수 있다.

1. **REST 철학을 수용하라**

   서비스에 대한 REST 방식은 서비스의 호출 프로토콜로 HTTP를 수용하고 표준 HTTP 동사를 사용하는 것이 핵심이다.
   HTTP 동사를 기반으로 기본 행동 양식을 모델링한다.

2. **URI를 사용해 의도를 전달하라**

   서비스의 엔드포인트로 사용되는 URI는 문제 영역에 존재하는 다양한 자원을 기술하고
   자원 관계에 대한 기본 메커니즘을 제공해야 한다.

3. **요청과 응답에 JOSN을 사용하라**

   JSON은 초경량 데이터 직렬화 프로토콜이며 XML보다 훨씬 사용하기 쉽다

4. **HTTP 상태 코드로 결과를 전달하라**

   HTTP 프로토콜에는 서비스의 성공과 실패를 명시하는 풍부한 표준 응답 코드가 있다.
   상태 코드를 익히고 모든 서비스에 일관되게 사용하느 것이 매우 중요하다.

모든 기본 지침은 서비스 인터페이스를 쉽게 이해하고 소비할 수 있게 만드는 것을 추구한다.
여러분은 개발자가 관심을 갖고 서비스 인터페이스를 살펴보고 바로 사용하길 원한다.
마이크로서비스가 사용하기 쉽지 않다면 개발자는 아키텍처의 본래 의도를 회피하고 와해하려고 할 것이다.



## 2.2 마이크로서비스를 사용하지 않아야 할 때

### 2.2.1 분산 시스템 구축의 복잡성

마이크로서비스는 잘게 나뉘고 분산되어 있어 모놀리식 애플리케이션에서 없던 복잡성을 가져온다.
마이크로서비스 아키텍처에는 높은 수준의 운영 성숙도도 필요하다.
고도로 분산된 애플리케이션을 성공시키는 데 필요한 자동화와 운영 작업 (모니터링과 확장)에 투자할 의사가 없는 조직이라면
고려하지 않는 것이 좋다.



### 2.2.2 서버 스프롤 (server sprawl)

마이크로서비스의 가장 일반적인 배포 모델 중 하나는 한 서버에 하나의 마이크로서비스 인스턴스를 배포하는 것이다.
대규모 마이크로서비스 기반 애플리케이션의 운영 환경에서만 구축 및 관리가 필요한 서버나 컨테이너가 50~100개 있을 수 있다.
클라우드에서 이들 서비스를 실행하는 데 드는 비용은 저렴하더라도 서버를 관리하고 모니터링하는 운영 작업은
엄청나게 복잡해질 수 있다.



### 2.2.3 애플리케이션 유형

마이크로서비스는 재사용성을 추구하며 높은 회복성과 확장성이 필요한 대규모 애플리케이션의 구축에 매우 유용하다.
소형 애플리케이션이나 소수 사용자를 위한 애플리케이션을 개발할 때 마이크로서비스아 같은 분산 모델로 구축한다면
구축에 따른 복잡성이 얻게 될 가치보다 더 클 수 있다.



### 2.2.4 데이터 변환과 일관성

마이크로서비스를 검토할 때 서비스의 데이터 사용 패턴과 서비스 소비자가 어떻게 서비스를 사용하는지 고민해야 한다.

애플리케이션이 여러 데이터 소스에서 복잡한 데이터를 취합하고 변환해야 할 경우
마이크로서비스의 분산된 특성 때문에 작업이 어려워진다.
과도한 책임을 떠안고 성능 문제에도 취약해질 것이다.

마이크로서비스 사이에 트랜잭션을 처리하는 표준이 없다는 사실도 잊지 말자.
트랜잭션 관리가 필요하다면 직접 만들어야 한다. 마이크로서비스는 메시지를 사용해 서로 통신할 수 있다.
메시징에서는 데이터를 업데이트할 때 지연 시간 (latency)이 발생한다.
따라서 업데이트한 데이터가 즉시 나타나지 않을 수도 있어 애플리케이션은 최종 일관성을 유지해야 한다.



## 2.3 개발자 이야기 : 스프링 부트와 자바로 마이크로서비스

### 2.3.3 마이크로서비스의 출입구 만들기 : 스프링 부트 컨트롤러

```java
[REST 이해]

- 서비스 호출 프로토콜로 HTTP를 사용한다
  서비스는 HTTP 엔드포인트로 노출되고 HTTP 프로토콜을
  사용해 서비스와 데이터를 교환한다
	
- 서비스의 행동 양식을 HTTP 표준 동사에 매핑한다
  REST는 서비스의 행동 양식을 HTTP 동사인 POST, GET, PUT, DELETE에 매핑할 것을 강조한다.
  그리고 이 동사는 대부분의 서비스에 있는 CRUD 함수에 매핑된다. 
	
- 서비스끼리 교환하는 모든 데이터의 직렬화 형식으로 JSON을 이용한다
  절대 불변 원칙은 아니지만 JSON은 입출력 데이터의 직렬화를 위한 공용어가 되었다.
  XML을 사용할 수도 있지만 많은 REST 기반 애플리케이션은 JSON을 더 많이 사용한다.
  JSON은 자바스크립트 기반 웹 프런트앤드와 서비스에 사용되는 데이터의
  직렬화 및 역직렬화를 위한 원시 형식이다.
	
- HTTP 상태 코드를 사용해 서비스 호출 상태를 전달한다
  HTTP 프로토콜은 풍부한 상태 코드를 제공해 서비스의 성공과 상태를 나타낼 수 있다.
  REST 기반 서비스는 HTTP 상태 코드와 리버스 프록시나 캐시 처럼 웹 기반
  인프라스터럭처를 활용해 비교적 쉽게 통합할 수 있다.
	
HTTP는 웹 언어이며, 서비스 구축을 위한 철학적 프레임워크로 HTTP를 사용하는 것은
클라우드에서 서비스를 구축하는 핵심이다
```

`@RestController` 를 사용하면 `Controller`클래스에서 `ReposneBody` 클래스로 반환할 필요가  없는데,
`@ResponeBody` 를 포함하는 `@RestController` 애너테이션에 의해 모두 처리되기 때문이다.

```java
[마이크로서비스에 JSON이 선택된 이유]

1. XML 기반의 SOAP와 비교할 때, JSON은 적은 텍스트로 데이터 표현이 가능하다는 점에서 매우 가볍다.
	
2. JSON은 가독성이 높고 사용하기 쉽다. 프로토콜이 단순해 작업을 아주 쉽게 처리할 수 있다.
	
3. JSON은 자바스크립트에서 사용되는 기본 직렬화 프로토콜이다.
   자바스크립트가 급격히 성장하여 JSON은 REST 기반 애플리케이션의 적임자가 되었다.
   프론트엔드 웹 클라이언트가 서비스를 호출하는 데 JSON이 사용되기 때문이다.

서비스 간 통신을 위해 JSON보다 더 효율적인 메커니즘과 프로토콜도 존재한다.
아파치 쓰리프트 프레임워크를 이용하면 바이너리 프로토콜도 서로 통신할 수 있는
다중 언어 서비스를 구축할 수 있다.
아파치 아브로는 클라이언트와 서버 호출 간 데이터를 바이너리 포맷으로
상호 변환할 수 있는 데이터 직렬화 프로토콜이다.

전송할 데이터 크기를 최소화할 필요가 있다면 이러한 프로토콜을 살펴보길 권장한다.
하지만 필자 경험상 마이크로서비스에서 JSON을 제대로 사용하면 효과적으로 작동했고
서비스 소비자와 서비스 클라이언트 간 디버깅을 위해 또 다른 통신 계층을 삽입할 필요가 없었다.
```



```tex
[엔드포인트 이름이 중요하다]

마이크로서비스를 너무 많이 작성하기 전에 여러분이 서비스가 노출하는 엔드포인트에
대한 표준을 수립했는지 확인해야 한다. 마이크로서비스의 URL은 서비스 의도,
서비스가 관리하는 리소스, 서비스 안에서 관리되는 리소스 사이에 존재하는 관계를
명확히 전달하는 데 사용해야 한다.

1. 서비스가 제공하는 리소스를 알 수 잇는 명확한 URL 이름을 사용하라
URL을 정의하는 데 표준 형식을 사용하면 API의 직관성과 사용 편의성이 향상된다.
일관된 명명 규칙을 사용한다.

2. 리소스 간 관계를 알 수 잇는 URL을 사용하라
마이크로서비스들이 가진 리소스 사이에서 부모-자식 관계가 생기는데, 외부에 부모
리소스 컨텍스트는 존재하지만 자식 리소스는 외부에 노출되지 않는 관계가 있다.
이러한 관계는 URL을 사용해 표현한다. 하지만 URL이 지나치게 길어지거나
중첩되는 경향이 있다면 해당 마이크로서비스가 너무 많은 일을 하려는 것일지도 모른다.

3. URL 버전 체계를 일찍 세워라
URL과 엔드포인트는 서비스 소유자와 서비스 소비자 간의 계약을 의미한다.
일반적 패턴 중 하나는 모든 엔드포인트 앞에 버전 번호를 붙이는 것이다.
일찍 버전 체계를 갖추고 준수하자. 소비자가 URL을 사용한 후 URL 버전 체계를
개량하는 것은 매우 어려운 일이다.
```



## 2.4 데브옵스 이야기: 혹독한 런타임 구축

데브옵스 엔지니어에게 마이크로서비스 설계란 양산(실운영) 이후의 서비스 관리에 관한 설계다.
코드 작성은 흔히 쉬운 부분에 속한다. 계속 동작하게 만드는 것이 어렵다.

책에서는 다음 네 가지 우너칙으로 마이크로 서비스 개발을 시작하고 실행해 볼 것이다.

1. 마이크로서비스는 단일 소프트웨어 산출물을 사용해 여러 서비스 인스턴스를 시작하거나 제거할 수 있도록
   **자체 완비형** (self-contained) 이며 **독립적으로 배포 가능** (independently deployable) 해야 한다.
2. 마이크로서비스는 **구성 가능** (configurable) 해야 한다.
   서비스 인스턴스가 시작될 때 구성에 필요한 데이터를 중앙에서 읽어 들이거나 환경 변수로 전달된 구성 정보를 받아야 한다.
   서비스를 구성하는 데 사람의 개입은 필요하지 않다.
3. 마이크로서비스 인스턴스는 클라이언트가 위치를 알지 못하도록 **투명해야** (transparent) 한다.
   클라이언트는 서비스의 정확한 위치를 알고 있어서는 안 된다.
   그 대신 마이크로서비스 클라이언트는 마이크로서비스 인스턴스의 물리적 위치를 모르더라도
   애플리케이션이 알 수 있도록 서비스 디스커버리 에이전트와 통신해야 한다.
4. 마이크로서비스는 자신의 상태를 **전달해야** 한다. 이는 클라우드 아키텍처에서 매우 중요한 부분이다.
   마이크로서비스 인스턴스들은 고장 날 수 있으며 클라이언트는 잘못된 서비스 인스턴스를 피해 라우팅해야 한다.

이 네 가지 원칙은 마이크로서비스 개발에서 발생하는 역설을 드러낸다.
마이크로서비스의 크기와 범위가 더 줄어들어도 이 마이크로서비스들을 사용하면 애플리케이션에는 동작 부분이 더 많아지는데,
마이크로서비스가 자체 분산 컨테이너에 분산되어 서로 독립적으로 실행되기 떄문에 이러한 현상은 더 심해진다.
이것은 고도의 조정 기술이 요구되고 더 많은 장애가 발생할 기회가 생긴다.

데브옵스 관점에서 마이크로서비스와 관련된 운영상의 요구 사항을 해결하고,
이러한 네 가지 원칙을 마이크로서비스를 빌드하고 환경에 배포할 때마다 발생하는 표준 수명 주기 이벤트로 변환해야 한다.
네 가지 원칙은 다음 운영상의 수명 주기 단계로 대응된다.

- **서비스 어셈블리**

  동일한 서비스 코드와 런타임을 정확히 같은 방식으로 배포하기 위해 반복성과 일관성을 보장하는
  서비스 패키징과 배포 방식은 무엇인가?

- **서비스 부트스트래핑**

  사람이 개입하지 않아도 모든 환경에 마이크로서비스 인스턴스를 신속하게 시작하고 배포하기 위해
  애플리케이션과 환경별 구성 코드를 런타임 코드와 분리하는 방법은 무엇인가?

- **서비스 등록 및 디스커버리**

  새로운 마이크로서비스 인스턴스가 배포될 때 다른 애플리케이션 클라이언트가 발견할 수 있게 만드는 방법은 무엇인가?

- **서비스 모니터링**

  마이크로서비스 환경에서 매우 높은 가용성을 요구하기 때문에 동일 서비스를 여러 인스턴스로 실행하는 것은 일반적이다.
  데브옵스 관점에서 마이크로서비스 인스턴스를 모니터링하고 마이크로서비스 고장을 회피하는 라우팅과
  비정상 서비스 인스턴스를 제거하는지 확인행 한다.

```java
[Twelve-Factor 마이크로서비스 서비스 애플리케이션 구축]

이 책을 향한 필자의 큰 바람 중 하나는 여러분이 성공적인 마이크로서비스 아키텍처를
위해 강력한 애플리케이션 개발과 데브옵스 실천이 필요합을 깨닫는 것이다.
이러한 실천의 간결한 요육 중 하나가 허로쿠의 Twelve-Factor 애플리케이션 선언이다.
이 문서는 항상 기억해야 할 12개의 모범 지침을 제공한다.
책을 읽으면서 이러한 실천 사항이 예제에 녹아 있는 것을 알 수 잇다.

- 코드베이스 (codebase)
  모든 애플리케이션 코드와 서버 프로비저닝 정보는 버전 관리되어야 한다.
  각 마이크로서비스는 소스 제어 시스템 안에 독립적인 코드 저장소를 가져야 한다.
	
- 의존성 (dependencies)
  애플리케이션이 사용하는 의존성을 메이븐 같은 빌드 도구를 이용해 명시적으로 선언해야 한다.
  제3자의 JAR 의존성은 특정 버전 번호를 붙여 명시해 선언해야 한다.
  따라서 동일 버전의 라이브러리를 사용해 항상 마이크로서비스를 빌드할 수 있다.
		
- 구성 (config)
  애플리케이션 구성(특히 환경별 구성)을 코드와 독립적으로 저장하자.
  애플리케이션 구성은 절대로 소스 코드와 동일한 저장소에 있으면 안된다.

- 백엔드 서비스 (backing services)
  마이크로서비스는 대게 네트워크를 거쳐 데이터베이스나 메시징 서비스와 통신한다.
  그렇다면 언제든 데이터베이스 구현을 자체 관리형 서비스에서 외부업체 서비스로
  교체할 수 있어야 한다. 10장에서 로컬에서 관리되는 Postgres 데이터베이스를
  AWS 데이터베이스로 옮기면서 이를 보여준다

- 빌드, 릴리스, 실행 (build, release, run)
  배포할 애플리케이션의 빌드, 릴리스, 실행 부분을 철저히 분리하라.
  코드가 빌드되면 개발자는 실행 중에 코드를 변경할 수 없다. 모든 변경 사항을
  빌드 프로세스로 되돌려 재배포해야 한다. 빌드된 서비스는 불변적이므로 변경할 수 없다. 

- 프로세스 (processes)
  마이크로서비스는 항상 무상태 방식을 사용해야 한다.
  서비스 인스턴스 손실에 의해 데이터가 손실될 것이라는 우려 없이 언제든 서비스를
  강제 종료하거나 교체할 수 있다.
	
- 포트 바인딩 (port binding)
  마이크로서비스는 서비스용 런타임 엔진을 포함한(실행 파일에 패키징된 서비스를 포함한)
  완전히 자체 완비형이다. 별도의 웹 또는 애플리케이션 서버 없이도 서비스는 실행되어야 한다.
  서비스는 명령행에서 단독으로 시작하고 노출한 HTTP 포트를 통해 즉시 엑세스할 수 있어야 한다.
	
- 동시성 (concurrency)
	확장해야 한다면 단일 서비스 안에서 스레드 모델에 의존하지 마라.
    그 대신 더 많은 마이크로서비스를 시작하고 수평 확장하라.
    마이크로서비스 안에서 스레드 사용을 배제하지는 않지만 확장을 위한 유일한 메커니즘으로 믿지 말라.
    수직 대신 수평 확장하라. 
	
- 폐기 기능 (disposability)
  마이크로서비스는 폐기 가능하므로 요구에 따라 싲가 및 중지할 수 있다.
  시작 시간은 최소화하고 운영 체제에서 강제 종료 신호를 받으면 프로세스는 적절히 종료해야 한다.

- 개발 및 운영 환경 일치 (dev/prod parity)
  서비스가 실행되는 모든 환경(개발자의 데스크톱 환경도 포함) 사이의 차이를 최소화 하라
  개발자는 서비스 개발을 위해 실제 서비스가 실행되는 동일한 인프라스트럭처를 로컬에 사용해야 한다.
  이는 환경 간 서비스 배포가 수 주가 아닌 수 시간 안에 이루어져야 한다는 것을 의미한다.
  코드가 커밋되자마자 테스트되고 가능한 신속하게 개발 환경에서 운영 환경으로 전파되어야 한다.

- 로그 (logs)
  로그는 이벤트 스트림이다.
  로그가 기록될 때 스플렁크나 Fluentd 같은 도구로 로그가 스트리밍되어야 한다.
  이들 도구는 로그를 수집해 중앙에 기록한다.
  마이크로서비스는 이러한 로깅 동작 방식에 신경 쓰지 않아야 하며,
  개발자는 표준 출력으로 출력된 로그를 시각적으로 확인할 수 있어야 한다.
	
- 관리 프로세스 (Admin processes)
  개발자는 종종 담당 서비스에 대해 데이터 마이그레이션이나 변환처럼 관리 작업을 수행해야 한다.
  이러한 작업은 임의로 수행되면 안 되고 소스 코드 저장소에 유지 및 관리되는 스크립트에 의해 수행되어야 한다.
  이 스크립트는 실행될 각 환경에 반복적으로 수행 가능하고 환경을 위해 변경되지 않아야 한다.
  즉 각 환경에 맞추어 스크립트를 수정하지 않는다.
```



### 2.4.1 서비스 어셈블리 : 마이크로서비스의 패키징과 배포

데브옵스 관점에서 볼 때 마이크로서비스 아키텍처의 핵심 개념 중 하나는 애플리케이션의 환경변화에 대응해
마이크로서비스의 여러 인스턴스를 신속하게 배포할 수 있다는 것이다.

이 개념을 충족하기 위해 마이크로서비스는 필요한 의존성을 모두 담아 단일 산출물로 패키징하고 설치될 수 있어야 한다.
그런 다음 이 산출물을 자바 JDK가 설치된 서버에 배포할 수 있다. 이러한 의존성에는 마이크로서비스르 호스팅하는
런타임 엔진 (HTTP 서버나 애플리케이션 컨테이너)도 포함된다.

일관된 구축, 패키징 및 배포하는 이과정을 서비스 어셈블리라고 한다.

모든 자바 마이크로서비스 프레임워크는 코드와 함께 패키징하고 배포할 수 있는 런타임 엔진을 포함한다.

```groovy
mvn clean package && java - jar target/licensing-service-0.0.1-SNAPSHOT.jar
```

애플리케이션 서버의 구성을 애플리케이션가 분리하므로 배포 과정에서 문제점이 발생하는데,
많은 조직에서 애플리케이션 서버의 구성을 소스 제어 저장소에 보관하지 않고 사용자 인터페이스와
자체 제작한 스크립트를 사용해 관리하는 것이 원인이다.

구성 편차가 너무 쉽게 애플리케이션 서버의 환경으로 유입되고 표면적으로는 무작위 장애로 보이는 것들을 불시에 야기 시킨다.

내장형 런타임 엔진을 포함한 단일 산출물로 배포하면 이러한 구성 편차 문제를 상당 부분 제거한다.
전체 산출물을 소스 제어하에 관리하므로 애플리케이션 팀이 애플리케이션 빌드와 배포 방법을 더 효과적으로 추론할 수 있다.



### 2.4.2 서비스 부트스트래핑: 마이크로서비스의 구성 관리

서비스 부트스트래핑은 마이크로서비스가 처음 가동할 때 시작하며 애플리케이션 구성 정보를 로드 한다.

애플리케이션 실행 중 행동 양식을 구성해야 할 때가 있다.
일반적으로 이 작업은 애플리케이션과 함께 배포된 프로퍼티 파일에서 애플리케이션 구성 데이터를 읽거나
관계형 데이터베이스 같은 데이터 저장소에서 데이터를 읽어 오는 작업들이다.

마이크로서비스에는 대개 동일한 형태의 구성 요구사항이 있다.
차이점은 클라우드에서 실행되는 마이크로서비스 애플리케이션에는 수백 개 또는 수천 개의
마이크로서비스 인스턴스를 실행할 수 있다는 것이다.
새로운 구성 데이터를 적용하기 위해 모든 서비스를 재배포하는 일은 불가능에 가깝다.

서비스 외부의 데이터 저장소에 데이터를 저장하면 이 문제가 해결되지만 클라우드의 마이크로서비스 상황에
몇 가지 고유한 난제가 있다.

구성 데이터는 구조가 단순한 편이고 일반적으로 자주 읽지만 자주 쓰지는 않는다.
데이터베이스는 단순한 키-값 짝보다 더 복잡한 데이터 모델을 관리할 목적으로 설계되었기 때문에
이 상황에서 관계형 데이터베이스를 사용하는 것은 과도하다.

1. 데이터는 정기적으로 액세스되지만 드물게 변경되므로 읽기 지연 시간이 짧아야 한다.
2. 데이터 저장소는 가용성이 좋아야 하고 읽기용 데이터 서비스에 근접해야 한다.
   구성 데이터 저장소는 애플리케이션의 단일 장애 지점이 될 수 있으므로 완전히 중단할 수 없다
3. 3장에서는 단순한 키-값 데이터 저장소를 사용해 마이크로서비스 애플리케이션의 구성 데이터를 관리하는 방법을 보여준다.
4. 

### 2.4.3 서비스 등록과 디스커버리: 클라이언트가 마이크로서비스와 통신하는 방법

클라우드 기반 서비스는 실행될 서버에 완전히 새로운 IP 주소를 할당받고 신속히 시작하고 제거될 수 있다.

서비스는 일시적이며 폐기 가능한 객체로 취급해야 한다는 주장 덕분에 마이크로서비스 아키텍처는
많은 서비스 인스턴스를 실행하며 고수준의 확장성과 가용성을 얻을 수 있었다.
상황에 따라 신속하게 서비스에 대한 요구와 회복성을 관리할 수 있다.
’일시적’ 서비스의 단점은 끊임없이 서비스의 시작과 종료를 반복하는 상황에서 일시적 서비스를
대량으로 수동 또는 직접 관리하면서 장애가 발생할 수 있다는 것이다.

마이크로서비스 인스턴스는 제3자 에이전트에 스스로 등록해야 하는데 이 등록 과정을 서비스 디스커버리라고 한다.
등록할 때 인스턴스의 물리적인 IP 주소 또는 도메인 주소와 애플리케이션이 서비스 검색에 사용할
논리적인 서비스 이름, 이 두가지 정보를 에이전트에 전달한다.



### 2.4.4 마이크로서비스의 상태 전달

서비스 디스커버리 에이전트는 클라이언트에 서비스 위치를 안내하는 교통 경찰 역할만 하는 것은 아니다.
서비스 디스커버리 에이전트는 등록된 각 서비스 상태를 모니터링 한다.
그리고 클라이언트가 고장 난 서비스를 호출하지 않도록 자신의 라우팅 테이블에서 문제가 된 서비스 인스턴스를 제거한다.

마이크로서비스가 실행되면 서비스 디스커버리 에이전트는 해당 서비스가 가용한지 확인하기 위해
상태 확인 인터페이스를 계속 모니터링하고 핑한다.

문제를 발견하면 망가진 인스턴스를 정지시키거나 새로운 서비스를 추가하는 등 조치를 취할 수 있다.

REST 기반 마이크로서비스 환경에서 상태 확인 인터페이스를 만드는 가장 단순한 방법은 JSON 페이로드와 HTTP 상태 코드를
반환하는 HTTP 엔드포인트를 노출하는 것이다.

스프링 부트를 사용하면 엔드포인트를 노출하기 쉬운데, 메이븐 빌드 파일을 수정해
스프링 액추에이터 (Spring Actuator) 모듈만 추가하면 된다.
스프링 액추에이터는 서비스 상태를 이해하고 관리하는 데 도움이 되는 엔드포인트를 기본 기능으로 제공한다.



## 2.5 모든 관점에서

클라우드에서 마이크로서비스는 언뜻 보기에 단순해 보이지만, 성공하려면 아키텍트와 개발자, 데브옵스 엔지니어의 관점을 모아
화합된 비전을 이루는 관점의 통합이 필요하다.

1. **아키텍트**

   비즈니스 문제의 실제 윤곽을 잡는다.
   비즈니스 문제 영역을 기술하고 이야기되는 스토리를 경청하고, 출현할 마이크로서비스 후보에 주시하자.
   굵게 나뉜 마이크로서비스에서 시작해서 작은 서비스로 리팩토링하는게 잘게 나뉜 것 보다 낫다.

2. **소프트웨어 엔지니어**

   서비스가 작다는 사실이 좋은 설계 원칙을 포기하라는 것은 아니다. 서비스 안의 각 계층이 개별 책임을 맡는
   계층적 서비스를 구축하는 데 집중한다.
   코드 내 프리엠워크를 만들려는 유혹을 피하고 완전히 독립적인 마이크로서비스를 지향한다.
   미숙한 프레임워크 설계와 도입은 애플리케이션의 수명 주기 후반에 막대한 유지 보수 비용을 초래할 수 있다.

3. **데브옵스 엔지니어**

   서비스는 외부와 단절된 것이 아니다. 서비스 수명 주기를 일찎 수립하자.
   서비스 빌드와 배포를 자동화하는 방법뿐 아니라 서비스 상태를 모니터링하고 문제가 발생할 때 대응하는 방법에도 집중해야 한다.

   

## 2.6 요약

- 마이크로서비스의 성공을 위해 아키텍트, 소프트웨어 개발자, 데브옵스 관점을 통합해야 한다.
- 마이크로서비스는 강력한 아키텍처 패러다임이지만 해택과 장단점이 있다.
  모든 애플리케이션이 마이크로서비스 애플리케이션일 필요는 없다.
- 아키텍트 관점에서 마이크로서비스는 작고, 자체 완비형이며 분산된 것이다.
  마이크로서비스는 좁은 범위와 소규모 데이터를 관리한다.
- 개발자 관점에서 REST 설계 방식과 서비스의 데이터 송수신을 위한 JSON을 사용해 마이크로서비스를 구축한다
- 데브옵스 관점에서 마이크로서비스를 패킺이, 배포, 모니터링하는 방법은 매우 중요하다
- 스프링 부트를 사용하면 서비스 하나의 JAR 실행 파일로 전달할 수 있다. JAR 파일에 내장된 톰캣 서버가 서비스를 호스팅 한다.
- 스프링 부트 프레임워크에 포함된 스프링 액추에이터는 서비스 런타임 정보와 함께 서비스의 운영 상태 정보도 제공한다.
- 

# 3장. 스프링 클라우드 컨피그 서버로 구성 관리

코드에 박힌 애플리케이션 구성 데이터는 구성을 변경할 때마다 애플리케이션을 재컴파일하거나 재배포해야 하므로 종종 문제가 된다.
이 문제를 피하기 위해 개발자는 애플리케이션 코드에서 구성 정보를 완전히 분리한다.

많은 개발자가 구성 정보를 저장하기 위해 저수준의 프로퍼티 파일 (yml, json 또는 xml)로 전환할 것이다.
대개 이러한 프로퍼티 파일은 데이터베이스 및 미들웨어의 접속 정보와 애플리케이션 행동 양식을 정하는
메타데이터가 존재하는 서버에 둔다.
애플로케이션을 프로퍼티 파일로 분리하는 것은 쉬우며, 대부분의 개발자는 구성 파일을 소스 관리 시스템에 넣거나
애플리케이션 일부로 배포하는 일 외에는 애플리케이션 구성을 위한어떤 운영 작업도 하지 않는다.

이러한 방식은 애플리케이션이 적은 상황에서는 적용될 수 있지만 수백 개의 마이크로서비스와 수많은 마이크로서비스 인스턴스가
실행되는 클라우드 기반의 애플리케이션 상황에서는 전혀 통하지 않는다.

클라우드 기반 환경에 놓인 애플리케이션 팀과 운영 팀이 어떤 구성 파일을 어디에 배치할지 정하기 위해 대혼란을 겪어야 하므로
갑자기 구성 관리는 중대한 문제가 된다. 따라서 클라우드 기반의 마이크로서비스 개발에서는 다음 사항이 강조된다.

1. 배포되는 실제 코드에서 애플리케이션의 구성을 완전하게 분리한다.
2. 서버 및 애플리케이션을 빌드하고 배포 환경에 따라 절대 바뀌지 않는 불변 이미지를 빌드한다.
3. 서버를 시작할 때 환경 변수나 애플리케이션의 마이크로서비스가 읽어 올 수 있는 중앙 저장소를 이용해
   애플리케이션 구성 정보를 주입한다.

이 장에서는 클라우드 기반의 마이크로서비스 애플리케이션에서 애프리케이션 구성 데이터를 관리하는 데
필요한 핵심 원칙과 패턴을 소개할 것이다.



## 3.1 구성(그리고 복잡성) 관리

마이크로서비스의 인스턴스는 사림이 최소한으로 개입해 신속하게 시작해야 하므로 클라우드에서 실행되는 마이크로서비스에
애플리케이션 구성 관리는 매우 중요하다.
항상 사람이 수동으로 구성하거나 배포하면 구성 편차 (configuration drift)와 예상하지 못한 장애, 애플리케이션 확장 요구에 대한
지체 시간이 발생할 수 있다.

애플리케이션 구성 관리를 위한 네 가지 원칙

1. **분리 (segregate)**

   물리적인 서비스의 배포와 서비스 구성 정보를 와전히 분리 애플리케이션 구성 정보를 서비스 인스턴스와 함께 배포하면 안된다.
   그 대신 환경 변수로 전달하거나 중앙 저장소에서 읽어와 구성 정보를 전달해야 한다.

2. **추상화 (abstract)**

   서비스 인터페이스 뒷 단에 있는 구성 데이터의 접근 방식을 추상화 한다.
   직접 엑세스하는 코드(파일이나 데이터베이스에서 데이터 읽기) 를 작성하기보다 REST 기반의 JSON 서비스를 사용해
   조회하게 만들어야 한다.

3. **중앙 집중화 (centralizae)**

   클라우드 기반의 애플리케이션에는 수많은 서비스가 존재하므로 구성 정보를 보관하는 저장소 개수를
   최소로 줄이는 것이 매우 중요하다.
   애플리케이션의 구성 정보를 가능한 소수 저장소에 집중화 한다

4. **견고성 (harden)**

   구성 정보를 배포된 서비스와 완전히 분리하고 중앙 집중화하므로 어떤 솔루션을 사용하더라도
   고가용성과 다중성을 구현할 수 있어야 한다

구성 정보를 실제 코드 외부로 분리하면 관리하고 버전 제어를 해야할 외부 의존성이 생긴다.
구성을 제대로 관리하지 못하면 탐지하기 어려운 버그와 예상하지 못한 장애를 만든다.



### 3.1.1 구성 관리 아키텍처

서비스가 부트스트래핑될 때 위 4가지 원칙들이 어떻게 적용되는지 보자

1. 마이크로서비스 인스턴스가 시작하면 서비스 엔드포인트를 호출해 동작 중인 환경별 구성 정보를 읽어 온다.
   구성 관리 서비스에 연결할 정보는 마이크로서비스가 시작할 때 전달된다
2. 실제 구성  정보는 저장소에 상주한다. 구성 저장소 구현방식은 관계형 데이터베이스,
   키-값 데이터 저장소 같은 다양한 방식이 존재한다
3. 애플리케이션 배포 방식과 독립적으로 애플리케이션의 구성 데이터를 관리한다
   빌드 및 배포 파이프라인으로 구성 관리를 변경하며, 변경된 구성은 버전 정보 태그를 달아 다른 환경에 배포될 수 있게 한다
4. 구성 관리가 변경되면 애플리케이션 구성 데이터를 사용하는 서비스는 변경 통보를 받고
   보유한 애플리케이션 데이터 사본을 갱신해야 한다.
5. 

### 3.1.2 구현 선택

책에서 스프링 클라우드 컨피그 서버를 선택한 이유는 다음과 같다

1. 스프링 클라우드 컨피그 서버는 쉽게 설치하고 사용할 수 있다
2. 스프링 클라우드 컨피그는 스프링 부트와 긴밀이 통합되어 있다.
   따라서 모든 애플리케이션의 구성 데이터를 사용이 간편한 애너테이션으로 읽어 올 수 있다.
3. 스프링 클라우드 컨피그 서버는 구성 데이터를 저장할 수 있는 여러 백엔드를 지원한다.
   유레카나 콘설 같은 도구를 이미 사용하고 있다면 바로 스프링 클라우드 컨피그 서버에 연결할 수 있다.
4. 스프링 클라우드 컨피그 서버는 깃 소스 제어 플랫폼과 직접 통합할 수 있다.
   스프링 클라우드 컨피그를 깃과 통합하면 다른 솔루션의 추가 의존성을 제거하고
   애플리케이션의 구성 데이터를 손쉽게 버전 관리를 할 수 있다
5. 

## 3.2 스프링 클라우드 컨피그 서버 구축

스프링 클라우드 컨피그 서버는 스프링 부트로 만든 REST 기반의 애플리케이션이다.
독립형 서버로 제공되지 않아 기존 스프링 부트 애플리케이션에 내장하거나 새로운 스프링 부트 프로젝트를 만들어
내장하는 방법으로 시작할 수 있다.

가장 먼저 할 일은 confsvr이라는 새로운 프로젝트 디렉터리를 만드는 일이다.
디렉터리 안에 스프링 클라우드 컨피그 서버를 시작하는데 필요한 JAR 파일을 내려받는 새로운 메이븐 파일을 생성한다.

컨피그 서버를 동작하게 하려면 여러 파일을 설정해야 한다. `application.yml`  파일에는 스프링 클라우드 컨피그 서비스가
수신 대기할 포트, 구성 데이터를 제공하는 백엔드 위치 등 정보를 명시한다.

스프링 클라우드 컨피그에서 모든 것은 계층 구조로 동작한다.
애플리케이션 구성은 애플리케이션 이름을 먼저 표시하고 구성 정보가 필요한 각 환경별 프로퍼티 파일로 구분한다.
각 환경에 두가지 구성 프로퍼티를 설정한다

- 라이선싱 서비스가 직접 사용할 예제 프로퍼티
- 라이선싱 서비스의 데이터가 저장될 Postgres 데이터베이스를 위한 데이터베이스 구성

애플리케이션 구성 파일의 명명 규칙은 appname-env.yml 이다. 환경 이름은 URL에 그대로 변환되어
구성 정보를 조회하는 데 사용된다.
서비스를 실행하려는 환경의 서비스를 시작하는 명령줄에서 전달된 스프링 부트 프로파일로 지정된다.
전달하지 않았다면 `application.yml` 이 디폴트다



### 3.2.1 스프링 클라우드 컨피그 부트스트랩 클래스 설정

`Application` 클래스에 `@EnableConfigServer` 어노테이션으로 서비스를 스프링 클라우드 컨피그 서비스로 사용 가능게 한다.



### 3.2.2 파일 시스템과 스프링 클라우드 컨피그 서버 사용

스프링 클라우드 컨피그 서버는 confsvr/src/main/resources/application.yml 파일의 항목을 사용해
애플리케이션 구성 데이터를 보관할 저장소를 지정한다.
파일 시스템 기반으로 한 저장소를 가장 쉽게 만들 수 있다.

```yaml
server:
	port : 8888
spring :
	profiles :
		active : native # 구성 정보를 저장할 백엔드 저장소(파일 시스템)
	cloud :
		config :
			server :
				native :
					searchLocations : file://Users/john... # 구성 파일 저장 경로
						
```

`http://localhost:8888/licensingservice/dev` 엔드포인트를 호출하면 기본(default) 과 dev,
두 환경에 있는 라이선싱 서비스의 구성 프로퍼티를 반환하는 것을 알 수 있다.

스프링 프레임워크가 프로퍼티를 분석하는 데 계층적 메커니즘으로 구현됐기 때문이다.
프로퍼티를 찾을 때 우선 기본 프로퍼티를 찾고 다음 해당 환경의 프로퍼티가 있다면 기본 프로퍼티를 대체한다.



## 3.3 스프링 클라우드 컨피그와 스프링 부트 클라이언트의 통합

라이선싱 서비스를 처음 시작할 때는 명령줄로 두 가지 정보 (스프링 프로파일과 스프링 클라우드 컨피그 서비스와 통신할 때
사용하는 엔드포인트)를 전달한다.
스프링 프로파일은 스프링 서비스가 추출하는 프로퍼티 환경에 매핑된다.

라이선싱 서비스가 처음 부팅함녀 전달받은 프로파일과 엔드포인트를 사용해 스프링 클라우드 컨피그 서비스와 통신한다.
스프링 클라우드 컨피그 서비스는 URI로 전달된 특정 스프링 프로파일에 해당되는 구성 정보를 뒷 단의 구성 저장소에서
조회한 후 적절한 프로퍼티 값을 라이선싱 서비스에 되돌려 준다.
스프링 부트 프레임워크는 이 프로퍼티 값을 애플리케이션에 적절히 삽입한다.



### 3.3.2 스프링 클라우드 컨피그를 위한 라이선싱 서비스 구성

메이븐 의존성을 정의한 후에는 라이선싱 서비스에 스 프링 클라우드 컨피그 서버의 위치를 알려주어야 한다.
스프링 클라우드 컨피그를 사용하는 스프링 부트 서비스의 구성 정보는 `bootstrap.yml` 과 `application.yml` 파일 중
한 곳에 설정된다.

`bootstrap.yml` 파일은 구성 정보가 사용되기 전에 애플리케이션 프로퍼티를 먼저 읽는다.

일반적으로 `bootstrap.yml` 파일에 서비스 애플리케이션 이름, 애플리케이션 프로파일과 스프링 클라우드 컨피그 서버에
접속할 수 있는 URI가 명시된다.
스프링 클라우드 컨피그 서버에 저장하지 않는, 즉 로컬에 유지하고 싶은 서비스 구성 정보는 `application.yml` 파일에 설정할 수 있다. 대개 스프링 클라우드 컨피그 서비스가 가용하지 않을 때도 사용할 수 있는 구성 데이터를 `applicaion.yml` 파일에 저장한다.

**라이선싱 서비스의 bootstrap.yml 구성**

```yaml
spring :
	application :
		name : licensingservice
	profiles :
		active :
			default
	cloud :
		config :
			uri : http://localhost:8888
			
환경 변수로 시작 정보 전달

클라우드 상황에서 필요한 애플리케이션의 구성 데이터 대부분은 구성 서버에
존재한다. 하지만 서비스를 시작하는 데 필요한 정보(예를 들어 구성 서버와
관련된 데이터)는 VM 인스턴스나 도커 컨테이너를 시작한 후 환경변수로 전달할 것이다.
```



### 3.3.4 `@Value` 애너테이션으로 프로퍼티 직접 읽기

스프링 데이터가 ‘저절로’ 데이터베이스의 구성 데이터를 데이터베이스 연결 객체에 주입하지만
다른 프로퍼티는 `@Value` 애너테이션을 사용해 주입해야 한다.

```java
@Component
public class ServiceConfig {
	@Value("${example.property}")
	private String examplePrepery;
	
}
**Tip :** 구성 값을 각 클래스 속성으로 직접 주입할 수도 있짐나, 모든 구성 정보를
하나의 구성 클래스로 츃합한 후 필요에 따라 개별 구성 클래스에 주입하면 유용하다
```



### 3.3.5 깃과 스프링 클라우드 컨피그 서버 사용

클라우드 기반의 애플리케이션에서 스프링 클라우드 컨피그 서버의 백엔드 저장소로 파일 시스템이 적합하지 않은 이유는
개발 팀이 컨피그 서버의 모든 인스턴스에 마운트될 공유 파일 시스템을 설정하고 관리해야 하기 때문이다.

깃을 사용하면 구성 관리 프로퍼티를 저장할 때 소스 관리의 모든 혜택을 누리고 빌드 및 배포 파이프라인에서
프로퍼티 구성 파일의 배포를 쉽게 통합할 수 있다.

**스프링 클라우드 컨피그용 `application.yml` 파일**

```yaml
server :
	port : 8888
spring :
	cloud :
		config :
			server :
				encrypt.enabled: false
				git : # 스프링 클라우드 컨피그에 백엔드 저장소로 깃을 사용
					uri : <http://github.com> ... # 깃 서버와 repo의 url을 전달
					searchPaths : licensingservice, orgranizationservice
					# 스프링 클라우드 컨피그에 구성 파일을 찾을 깃 경로를 전달한다
					username : native-cloud-apps
					password : Offended
```



### 3.3.6 스프링 클라우드 컨피그 서버에서 프로퍼티 갱신

스프링 클라우드 컨피그 서버를 사용할 때 프로퍼티가 변경될 때 스프링 클라우드 컨피그 서버가
어떻게 동적으로 애플리케이션을 갱신하는가?

스프링 클라우드 컨피그 서버는 항상 최신 버전의 프로퍼티를 제공한다.
하부 저장소의 프로퍼티를 변경하면 바로 반영한다.

하지만 스프링 부트 애플리케이션은 시작할 때만 프로퍼티를 읽어 오며 스프링 클라우드 컨피그 서버에서
변경된 프로퍼티를 자동으로 읽어 오지 않는다.

스프링 부트 액추에이터는 `@RefreshScope`  애너테이션을 제공하므로 스프링 부트 애플리케이션이 /refesh 엔드포인트를 사용해
애플리케이션 구성 정보를 다시 읽어 올 수 있다.

```java
@SpringBootApplication
@RefreshScope
public class Application {
	public static void main(String[] args) {
		SpringApplication.run(Application.class, args);
	}
}
```

`@RefreshScope` 애너테이션에 대해 두 가지 사항을 유의하자.
첫째 이 애너테이션은 애플리케이션 구성에 있는 사용자 정의 스프링 프로퍼티만 다시 로드한다.
즉 데이터베이스 구성 정보처럼 스프링 데이터에서 정의된 구성은 `@RefeshScope` 애너테이션으로 다시 로드하지 않는다.

```
[마이크로서비스 구성 정보 업데이트]

스프링 클라우드 컨피그 서비스를 마이크로서비스와 함께 사용할 때 프로퍼티를
동적으로 변경하기 전에 고려할 사항 중 하나는 동일한 서비스 인스턴스가 다수
실행 중이고 새로운 애플리케이션 구성으로 모든 서비스를 업데이트해야 한다는 것이다.
이 문제에 접근할 수 있는 몇 가지 방법이 있다.

스프링 클라우드 컨피그 서비스는 이 서비스를 사용하는 모든 클라이언트에
변경이 일어났다고 알려 주는 스프링 클라우드 버스(Spring Cloud Bus)라는
'푸시(push)' 기반의 메커닞므을 제공한다. 스프링 클라우드 컨피그는
RabbitMQ 같은 미들웨어를 추가해야 한다. 변경을 감지하는 매우 유용한 방법이지만
모든 스프링 클라우드 컨피그 백엔드가 콘설 서버처럼 푸시 메커니즘을 지원하는 것은
아니다

다음 장에서 스프링 서비스 디스커버리와 유레카를 사용해 모든 서비스 인스턴스를
등록할 것이다. 애플리케이션 구성 정보의 업데이트 이벤트를 처리하는 필자의
다른 방법은 스프링 클라우드 컨피그의 애플리케이션 프로퍼티를 업데이트한 후
서비스 디스커버리 엔진으로 모든 서비스 인스턴스를 조회해 /refesh 앤드포인트를
직접 호출하는 간단한 스크립트를 작성하는 것이다

마지막 방법은 모든 서버와 컨테이너가 새로운 프로퍼티를 업데이트 하도록 재시작하는
것이다. 특히 도커 같은 컨테이너에서 서비스를 실행하고 있다면 훨씬 수월하다.
도커 컨테이너는 수초 만에 재시작해 애플리케이션 구성을 다시 읽어올 수 있다.

클라우드 기반 서버의 일시적(ephemeral)인 특징을 기억하자.
새로운 구성으로 새로운 서비스 인스턴스를 시작해 그것으로 트래픽을 유입시키고
오래된 인스턴스를 제고하는 것을 두려워하지 말자.
```



## 3.4 중요한 구성 정보 보호

스프링 클라우드 컨피그 서버는 모든 프로퍼티를 애플리케이션 구성 파일에 평문으로 저장하는 것이 기본 설정이다.
하지만 데이터베이스 자격 증명처럼 중요한 정보도 구성 파일에 포함된다.

스프링 클라우드 컨피그는 중요한 프로퍼티를 쉽게 암호화할 수 있는 기능을 제공하여 대칭 및 비대칭 암호화를 모두 지원한다.

대칭 키를 사용해 암호화하는 스프링 클라우드 서버의 설정 방법을 알아볼 것이다. 암호화를 적용하기 위해 다음 단계를 거쳐야 한다.

1. 암호화에 필요한 오라클 JCE jar 파일을 내려받고 설치한다

2. 암호화 키를 설정한다

3. 프로퍼티를 암호화 및 복호화한다

4. 클라이언트 측에서 암호화하도록 마이크로서비스를 구성한다

   

### 3.4.1 암호화에 필요한 오라클 JCE jar 파일을 내려받아 설치

먼저 오라클의 JCE 를 내려받아 설치해야 한다. 메이븐으로 할 수 없으므로 오라클사에서 직접 내려받아야 한다.



### 3.4.2 암호화 키 설정

JAR 파일이 준비되면 대칭 암호화 키를 설정해야 한다. 대칭 암호화 키는 암호자가 값을 암호화하고 복호자가 복호화하는 데
사용하는 공유된 비밀 키에 불과하다.
스프링 클라우드 컨피그 서버에서 사용되는 대칭 암호화 키는 ENCRYPT_KEY라는 운영 체제의 환경 변수를 사용해
서비스에 전달되는 선택된 문자열이다.

대칭 키에 대해 다음 두 가지를 유의한다.

1. 대칭 키의 길이는 12자 이성이어야 하며, 불규칙 문자열이 이상적이다.
2. 대칭 키를 분실하면 안 된다. 암호화 키로 한번 암호화한 것은 그 키 없이는 복호화할 수 없다.

```
[암호화 키 관리]

- 실제 배포에서는 환경별로 다른 암호화키를 사용하고 무작위 문자를 키로 사용
- ENCRYPT_KEY 환경 변수는 하드코딩 하지 않고 환경 변수로 참조하자
```



### 3.4.3 프로퍼티 암호화 및 복호화

데이터베이스 패스워드를 암호화 할 것이다. 현재 `spring.datasource.password` 프로퍼티는 평문으로 설정되어 있다.
스프링 클라우드 컨피그 인스턴스가 실행할 때 ENCRYPT_KEY 환경 변수가 설정되었음을 감지하고
2개의 새로운 엔드포인트 (/encrypt와 /decrypt)를 스프링 클라우드 컨피그 서비스에 자동으로 추가한다.
/encrypt 엔드포인트를 사용해 password를 암호화 한다

/encrypt 에 POST 요청으로 Body에 password를 보내면 암호화된 결과를 받을 수 있다.

이제 암호화된 프로퍼티를 추가할 수 있다.

```yaml
spring.datasource.password: “{cipher} encryptedpassword”
```

하지만 /default 엔드포인트를 호출했을 때 데이터베이스 패스워드가 평문으로 표시되는 문제가 존재한다.

기본적으로 스프링 클라우드 컨피그 서버에서 모든 프로퍼티를 복호화를 수행하고
그 결과를 프로퍼티를 사용하는 애플리케이션에 평문으로 전달한다.
하지만 스프링 클라우드 컨피그 서버가 복호화하지 않고 구성 데이터를 조회하는 애플리케이션이
암호화된 프로퍼티를 복호화하는 책임을 지도록 설정할 수 있다.



### 3.4.4 클라이언트 측에서 암호화하도록 마이크로서비스 구성

클라이언트 측에서 복호화하려면 다음 세 단계를 수행해야 한다.

1. 서버 측에서 프로퍼티를 복호화하지 못하도록 스프링 클라우드 컨피그를 설정한다
2. 라이선싱 서버에서 대칭 키를 설정한다
3. 라이선싱 서비스의 pom.xml 파일에 psring-security-rsa JAR 파일을 추가한다

가장 먼저 해야 할 일은 스프링 클라우드 컨피그의 서버 측 복호화 프로퍼티를 비활성하는 것이다.
스프링 클라우드 컨피그의 `bootstrap.yml` 파일에 있는 `spring.cloud.config.server.encrypt.enabled` 프로퍼티를
`false`로 설정하면 비활성화 할 수 있다.

이제 복호화는 애플리케이션에서 담당하므로 스프링 클라우드 컨피그 서버에 사용될 ENCRYPT_KEY 환경 변수가 동일한 대칭키로
설정되어 있는지 확인하고 라이선싱 서비스에서 대칭 키를 먼저 설정해야 한다.

그 다음에 라이선싱 서비스에 spring-security-rsa JAR 의존성을 추가해야 한다

이 JAR 파일에는 스프링 클라우드 컨피그 서버에서 전달된 암호화된 프로퍼티를 복호화하는 데 필요한 스프링 코드가 들어 있다. http:localhost:8888/licensingservice/default 엔드포인트를 호출하면 암호화된 형식으로 `spring.datasource.password`가 표시된다.



## 3.5 마치며

애플리케이션 구성 관리는 평범해 보여도 클라우드에 기반을 둔 환경에서는 매우 중요하다.
애플리케이션과 서버가 불변하고 여러 환경에 배포되는 어떤 서버도 수작업으로 구성하지 않아야 한다.
하지만 이 모델은 JAR나 WAR 파일처럼 애플리케이션 산출물과 프로퍼티를 고정된 환경에 함께 배포하는
전통적인 배포 모델과는 상충된다.

클라우드에 기반을 둔 모델에서는 애플리케이션 구성 데이터를 애플리케이션과 완전히 분리하고
적절한 구성 데이터를 런타임에 중비할 수 있어 동일한 서버와 애플리케이션 산출물을 모든 환경에 일관되게 적용할 수 있다.



## 3.6 요약

- 스프링 클라우드 컨피그 서버를 사용하면 애플리케이션 프로퍼티를 환경별로 설정할 수 있다
- 스프링은 스프링 프로파일을 사용해 스프링 클라우드 컨피그 서비스에서 조회할 환경 프로퍼티를 결정하고 서비스를 시작한다
- 스프링 클라우드 컨피그 서비스는 파일이나 깃 기반의 애플리케이션 저장소를 사용해 애플리케이션 프로퍼티를 저장할 수 있다
- 스프링 클라우드 컨피그 서비스는 대칭 및 비대칭 암호화를 사용해 중요한 정보를 암호화할 수 있다.



# 4장. 서비스 디스커버리

**서비스 디스커버리**
분산 아키텍처에서 시스템의 물리적 위치 주소를 찾는 것
애플리케이션에서 사용하는 모든 원격 서비스의 주소가 포함된 프로퍼티 파일을 관리하는 것 처럼 단순하거나
UDDI(Universal Description, Discovery, and Integration)  저장소처럼 정형화 되고 복잡한 것일 수 있다.

**서비스 디스커버리가 중요한 이유**

1. 해당 환경에서 실행하는 서비스 인스턴스 개수를 신속하게 수평 확장하거나 축소할 수 있다.

   - 서비스의 물리적 위치가 서비스 소비자에게 드러나지 않는다.

   - 서비스 소비자가 실제 서비스 인스턴스의 물리적 위치를 모르기 때문에
     서비스 풀에서 새로운 서비스 인스턴스의 추가나 삭제가 자유롭다.

     - 이로인해 서비스의 수직 확장만이 유일한 확장이 아닌
       수평 확장하는 더 강력한 접근 방식으로 사고 전환을 할 수 있다.

     - 배포가 서비스 소비자와 별개로 진행되도록 추상화에 도움을 준다.

2. 애플리케이션 회복성 향상에 도움을 준다.
   - 마이크로서비스 인스턴스가 비정상이거나 가용하지 않다면
     내부 가용 서비스 목록에서 해당 인스턴스를 제거한다.
   - 사용할 수 없는 서비스를 피해 라우팅하므로 다운된 서비스가 야기한 피해를 최소화 한다.



## 4.1 서비스 위치 찾기

애플리케이션에서 여러 서버로 분산된 자원을 호출할 때마다 해당 자원의 물리적 위치를 찾아야 한다.
클라우드가 아닌 환경에서 위치 확인은 대개 DNS와 네트워크 로드 밸런서로 해결되었다.

애플리케이션은 다른 조직에 있는 서비스를 호출하기 위해 서비스를 대표하는 고유 경로와 함께
일반적인 DNS 이름을 사용해 서비스 호출을 시도한다.

서비스 소비자에게 요청을 받으면 로드 밸런서는 사용자가 액세스하려는 경로를 기반으로
라우팅 테이블에서 물리적 주소 항목을 찾는다.
라우팅 테이블 항목에는 해당 서비스를 호스팅하는 서버가 1개 이상 포함된 서버 목록이 있다.
로드 밸런서는 서버 목록에서 하나를 선택해 요청을 전달한다.

서비스의 각 인스턴스는 여러 애플리케이션 서버에 배포된다.
애플리케이션 서버 개수는 **정적**이며 **영구적인** 경우가 많다.
(서버가 비정상적으로 종료되면, 전과 동일한 상태와 동일한 IP 및 구성으로 복원될 것이다.

이러한 모델 유형은 회사 데이터센터 안에서 실행되는 애플리케이션과 정적 서버 그룹에서 실행되는
소수 서비스에서는 잘 동작한다.
하지만 클라우드 기반의 마이크로 서비스 애플리케이션에서는 그러지 못하다.

**로드밸런서가 마이크로 서비스 애플리케이션에 적합하지 않은 이유**

- **단일 장애 지점**

  로드 밸런서가 고가용성을 지원한다 해도 여전히 전체 인프라스트럭처의 단일 장애 지점이다.
  로드 밸런서가 다운되면 로드 밸런서에 의존하는 모든 애플리케이션도 다운된다.
  로드 밸런서를 고가용하게 만들더라도 애플리케이션 인프라 스트럭처 안에서
  집중화된 병목 지점이 될 가능성이 높다.

- **수평 확장의 제약성**

  로드 밸런서 클러스터에 서비스를 모아 연결하므로 부하 분산 인프라스트럭처를 여러 서버에
  수평적으로 확장할 수 있는 능력이 제한된다.

  대부분 상용 로드 밸런서는 이중화를 위해 핫스왑 모델에 따라 부하를 처리하는데
  하나의 서버만 사용하고, 보조 로드밸런서는 주 로드 밸런서에 장애가 발생할 경우 대체 작동용이다.
  본질적으로 하드웨어의 제약을 받는다.

  상용로드 밸런서는 가변 모델이 아닌 고정 용량에 맞추어 한정된 라이선싱 모델을 보유한다.

- **정적 관리**

  전통적 로드 밸런서 대부분은 서비스를 신속히 등록하고 취소하도록 설정되지 않았다.
  중앙 집중식 데이터베이스를 사용해 경로 규칙을 저장하고 대개 공급업체의 독점적인 API를
  사용해야만 새로운 경로를 지정할 수 있다.

- **복잡성**

  로드 밸런서가 서비스에 대한 프록시 역할을 하므로 서비스 소비자에게 요청할 때
  물리적인 서비스에 매핑된 요청 정보가 있어야 한다.

  이 변환 계층은 서비스 매핑 규칙을 수동으로 정의하고 배포해야 하므로
  서비스 인프라스트럭처의 복잡성을 가중시킨다.

  전통적 로드 밸런서 시나이로에서 새로운 서비스를 인스턴스의 시작 시점이 아닌 수동으로 등록했다.



로드 밸런서는 대부분의 애플리케이션이 중앙 집중화된 네트워크 인프라스트럭처를 이용해
처리될 수 있는 크기와 규모가 있는 기업환경에서 잘 동작한다.

게다가 SSL 종료를 한곳에서 처리하고 서비스의 포트 보안을 관리하는 면에서 여전히 중요한 역할을 한다.
로드 밸런서는 자기 후방의 모든 서버에 대한 인바운드 및 아웃바운드 포트 접근을 제어할 수 있다.

PCI (Payment Card Industry) 법규준수처럼 산업 표준의 인증 요구 사항을 충족하려고 할때
이러한 최소 네트워크 접근 개념은 종종 중요한 구성 요소다. 

하지만 대용량의 트랜잭션과 중복성 (redundancy)을 처리해야 하는 클라우드에서
중앙 집중식 네트워크 인프라스트럭처는 효율적으로 확장되지 않고 비용 효율도 낮아서
결국 제대로 동작하지 못한다.



## 4.2 클라우드에서 서비스 디스커버리

클라우드 기반 마이크로서비스 환경에 대한 솔루션은 다음 기능을 갖춘 서비스 디스크버리
메커니즘을 사용하는 것이다.

- **고가용성**(highly available)

  서비스 디스커버리는 서비스 검색 정보를 서비스 디스커버리 클러스터의 여러 노드가 공유하는
  '핫' 클러스터링 환경을 지원행 한다.
  한 노드가 사용할 수 없게 되면 클러스터의 다른 노드가 인계를 받을 수 있어야 한다.

- **피어 투 피어** (P2P, Peer-to-Peer)

  서비스 디스커버리 클러스터의 각 노드는 서비스 인스턴스의 상태를 공유한다.

- **부하 분산** (load balancing)

  서비스 디스커버리는 요청을 동적으로 부하 분산해서 서비스 디스커버리가 관리하는
  모든 서비스 인스턴스에 분배해야 한다.

- **회복성** (resilent)

  서비스 디스커버리 클라이언트는 서비스 정보를 로컬이 '캐시' 해야한다.
  로컬 캐싱은 서비스 디스커버리 기능을 점진적으로 저하시킬 수 있는데
  서비스 디스커버리 서비스가 가용하지 않을 때 애플리케이션이 로컬 캐시에 저장된 정보를 기반으로
  서비스를 계쏙 찾을 수 있고 동작하게 한다.

- **장애 내성** (fault-tolerant)

  서비스 디스커버리는 서비스 인스턴스의 비정상을 탐지하고 가용 서비스 목록에서
  인스턴스를 제거해야 한다.
  이러한 작업을 사람의 개입 없이 조치를 취해야 한다.

  

### 4.2.1 서비스 디스커버리 아키텍처

서비스 디스커버리 아키텍처를 논의하려면 네 가지 개념을 이해해야 한다.

- **서비스 등록** (service registration)

  서비스를 서비스 디스커버리 에이전트에 어떻게 등록하는가?

- **클라이언트가 서비스 주소 검색** (client lookup of service address)

  서비스 클라이언트가 어떻게 서비스 정보를 검색하는가?

- **정보 공유** (information sharing)

  서비스 정보를 노드 간에 어떻게 공유하는가?

- **상태 모니터링** (health monitoring)

  서비스가 자신의 상태 정보를 서비스 디스커버리 에이전트에 어떻게 전달하는가?

![서비스 디스커버리 아키텍처](https://github.com/devMuscle/TIL/blob/main/images/README/%EC%84%9C%EB%B9%84%EC%8A%A4%20%EB%94%94%EC%8A%A4%EC%BB%A4%EB%B2%84%EB%A6%AC%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98.png)

서비스 인스턴스가 시작하면 서비스 디스커버리 인스턴스가 접근할 수 있는
자신의 물리적 위치와 경로, 포트를 등록한다.
서비스의 각 인스턴스에는 고유한 IP 주소와 포트가 있지만 동일한 서비스 ID로 등록한다.
이때 서비스 ID는 동일한 서비스 인스턴스 그룹을 고유하게 식별하는 키일뿐이다.

서비스는 일반적으로 1개의 서비스 디스커버리 인스턴스에만 등록한다.
서비스 디스커버리 구현체들은 대부분 P2P 모델을 사용해 서비스 인스턴스의 데이터를
클러스터에 있는 다른 노드에 전파한다.

서비스 디스커버리 구현에 따라 전파 매커니즘에 하드 코딩된 서비스 목록을 사용하거나
gossip 같은 다중 캐스트 프로토콜 및 'infection-style' 프로토콜을 사용해 클러스터에서
발생된 변경을 다른 노드가 '발견(discovery)' 할 수 있다.

마지막으로 각 서비스 인스턴스는 자기 상태를 서비스 디스커버리 서비스에 푸시하거나
서비스 디스커버리 서비스가 인스턴스 상태를 추출한다.
정상 상태를 반환하지 못한 서비스는 가용한 서비스 인스턴스 풀에서 제거된다.

서비스가 서비스 디스커버리 서비스에 등록되면 그 서비스의 기능을 사용해야 하는 애플리케이션이나
따른 서비스에서 사용할 준비가 된 것이다.
클라이언트가 서비스를 '발견'하기 위한 다른 모델도 존재한다.
클라이언트는 서비스 디스커버리 엔진에만 의존해 서비스가 호출될 때마다 서비스 위치를 확인한다.
이 방법을 사용하면 등록된 마이크로서비스 인스턴스를 호출할 때마다 서비스 디스커버리 엔진이 호출된다.
아쉽게도 이 방식은 서비스 클라이언트가 서비스를 찾고 호출하기 위해 서비스 디스커버리 엔진에
전적으로 의존하므로 취약하다.

더 견고한 방식은 **클라이언트 측** 부하 분산이라는 방법을 사용하는 것이다.

이 모델에서 소비 행위자가 서비스를 호출해야 할 때는 다음과 같이 한다.

1. 서비스 소비자가 요청한 모든 서비스 인스턴스를 위해 서비스 디스커버리 서비스에 접속한 후
   데이터를 서비스 소비자 기기에 로컬 캐시한다.

2. 클라이언트가 서비스를 호출하려고 할 때마다 서비스 소비자는 캐시에서 위치 정보를 검색한다.
   일반적으로 클라이언트 측 캐싱은 '라운드로빈' 부하 분산 알고리즘처럼 단순한 알고리즘을 사용해
   서비스 호출을 여러 인스턴스로 분산한다.

3. 클라이언트는 주기적으로 서비스 디스커버리 서비스에 접속해 서비스 인스턴스 캐시를 새로고침한다.
   클라이언트 캐시는 최종 일관성을 유지하지만, 클라이언트가 목록을 새로고침 하기 위해
   서비스 디스커버리 인스턴스에 접속하고 서비스에 호출할 때 비정상적인 서비스 인스턴스를
   호출할 위험성은 항상 존재한다.

   서비스를 호출하는 동안 서비스 호출이 실패하면 로컬에 있는 서비스 디스커버리 캐시가 무효화되고
   서비스 디스커버리 클라이언트는 서비스 디스커버리 에이전트에 모록 새로고침을 시도한다.



### 4.2.2 스프링과 넷플릭스 유레카를 사용한 서비스 디스커버리

스프링 클라우드와 넷플릭스의 유레카 서비스 디스커버리 엔진을 사용해
서비스 디스커버리 패턴을 구현 가능하며,
클라이언트 측 부하 분산을 위해 스프링 클라우드와 넷플릭스으 리본 라이브러리를 사용할 수 있다.

1. 서비스 부트스트래핑 시점에 라이선싱 및 조직 서비스는 자신을 유레카 서비스에 등록한다.
   이 등록 과정에서 서비스 ID와 함께 각 서비스 인스턴스의 물리적 위치, 포트 번호를 유레카에 알려준다.
2. 라이선싱 서비스가 조직 서비스를 호출할 때 넷플릭스 리본 라이브러리를 사용해 클라이언트측
   부하 분산 기능을 수행한다.
   리본 라이브러리는 유레카서비스에서 서비스의 위치 정보를 조회하고 로컬에 캐싱한다.
3. 주기적으로 넷플릭스 리본 라이브러리는 유레카 서비스를 핑해서 로컬 캐시의 서비스 위치를 새로고침 한다.



## 4.6 요약

- 서비스 디스커버리 패턴은 서비스의 물리적 위치를 추상화하는 데 사용한다.
- 유레카 같은 서비스 디스커버리 엔진은 서비스 클라이언트에 영향을 주지 않고 해당 환경의
  서비스 인스턴스를 원활하게 추가, 삭제할 수 있다.
- 클라이언트 측 부하 분산을 사용하면 서비스를 호출하는 클라이언트에서 서비스의 물리적 위치를 캐싱해
  더 나은 성능과 회복성을 제공할 수 있다.
- 유레카는 넷플릭스 프로젝트의 스프링 클라우드와 사용하면 쉽게 구축하고 구성할 수 있다.
- 스프링 클라우드와 넷플릭스 유레카, 그리고 서비스를 호출하는 렛플릭스 리본으로
  다음 세가지 메커니즘을 사용했다.
  - 스프링 클라우드와 `DiscoveryClient`
  - 스프링 클라우드와 리본 지원 `RestTemplate`
  - 스프링 클라우드와 넷플릭스 `Feign` 클라이언트



# 5장. 나쁜 상황에 대비한 스프링 클라우드와 넷플릭스 히스트릭스의 클라이언트 회복성 패턴

모든 시스템에서 장애에 대응하는 애플리케이션 구축 방법을 찾는 것은 개발자에게 중요하다.

대부분은 인프라스트럭처나 핵심 서비스의 완전한 장애만 고려한다.
핵심 서버를 클러스터링하고, 서비스의 부하를 분산하며 인프라스트럭처를
여러 곳으로 분리하는 기술을 사용해 애플리케이션 각 계층의 중복성을 높이는데 주력한다.

이러한 접근 방식은 시스템 컴포넌트가 완전히 손실된 것을 고려하지만 회복력있는 시스템을
구축하는 데 생기는 사소한 문제만 해결할 뿐이다.
서비스 하나가 충돌하면 쉽게 감지할 수 있고 애플리케이션은 그 서비스를 피해 우회할 수 있다.
하지만 서비스가 느려질 때 성능 저하를 감지하고 우회하는 것은 다음 이유로 매우 어렵다.

1. **서비스 저하는 간헐적으로 발생하고 확산될 수 있다.**

   서비스 저하는 사소한 부분에서 갑자기 발생할 수 있다.
   순식간에 스레드 풀을 모두 소진해 완전히 무너지기 전까지 장애 징후는
   일부 사용자가 문제점을 불평하는 정도로 나타날 것이다.

2. **원격 서비스 호출은 대개 동기식이며 오래 걸리는 호출을 중단하지 않는다.**

   서비스 호출자에게는 호출이 영구 수행되는 것을 방지하는 타임아웃 개념이 없다.
   서비스를 호출해 작업을 수행하고 서비스가 응답할 때까지 대기한다.

3. **애플리케이션은 대개 부분적인 저하가 아닌 원격 자원의 완전한 장애를 처리하도록 설계된다.**

   서비스가 완전히 다운되지 않는다면 애플리케이션이 서비스를 계속 호출하고
   빨리 실패하지 않는 일이 자주 발생한다.

   애플리케이션은 제대로 동작하지 않는 서비스를 계속 호출할 것이다.
   호출하는 서비스는 정상적으로 저하될 수도 있지만 자원 고갈로 비정상적으로 종료될 가능성이 높다.

   **자원 고갈** (resource exhaustion) 이란 스레드 풀이나 데이터베이스 커넥션 같은 제한된 자원이
   한계를 넘으면 호출 클라이언트가 그 자원이 가용해질 때까지 대기해야 하는 상황이다.



제대로 동작하는 원격 서비스로 야기되는 문제가 심각한 이유는 탐지하기 어려울 뿐만 아니라
애플리케이션 전체 생태계에 미치는 파급 효과가 크기 때문이다.
안전 장치가 없다면 서비스 하나가 여러 애플리케이션을 다운시킬 수 있다.

클라우드와 마이크로서비스에 기반을 둔 애플리케이션은 사용자 트랜잭션을 완료하는 데 필요한
여러 인프라스트럭처 위에서 세밀하게 분산된 수 많은 서비스로 구성되기 때문에 이러한점에 특히 더 취약하다.



## 5.1 클라이언트 회복성 패턴이란?

클라이언트 회복성 패턴을 위한 소프트웨어 패턴은 원격 서비스가 에러를 던지거나 제대로 동작하지 못해
원격 자원의 접근이 실패할 때, 원격 자원을 호출하는 클라이언트 충돌을 막는 데 초점이 맞춰져 있다.

이 패턴의 목적은 데이터베이스 커넥션 및 스레드 풀 같은 소중한 클라이언트의 소비자에게
'상향 (upstream)' 전파되는 것을 막는다.



### 5.1.1 클라이언트 측 부하 분산

클라이언트가 넷플릭스 유레카 같은 서비스 디스커버리 에이전트를 이용해
서비스의 모든 인스턴스를 검색한 후 해당 서비스 인스턴스의 실제 위치를 캐싱한다.

서비스 소비자가 서비스 인스턴스를 호출해야 할 때마다 클라이언트 측 로드 밸런서는
서비스 위치 풀에서 관리하는 서비스 위치를 하나씩 전달한다.



### 5.1.2 회로 차단기 (Circuit Breaker)

소프트웨어 회로 차단기는 원격 서비스 호출을 모니터링한다.
호출이 오래 걸린다면 회로 차단기가 중재해 호출을 중단한다.
회로 차단기는 원격 자원에 대한 모든 호출을 모니터링하고, 호출이 필요한 만큼 실패하면
회로 차단기가 활성화되어 빨리 실패하게 만들며, 고장 난 원격 자원은 더 이상 호출되지 않도록 차단한다.



### 5.1.3 폴백 처리 (Fallback)

폴백 패턴을 사용하면 원격 서비스에 대한 호출이 실패할 때 예외 (Exception) 를 발생시키지 않고
서비스 소비자가 대체 코드 경로로 실행해 다른 방법으로 작업을 수행할 수 있다.

일반적으로 이 패턴은 다른 데이터 소스에서 데이터를 찾거나 향후 처리를 위해 사용자 요청을
큐 (queue) 에 입력하는 작업과 연관된다.
사용자 호출에 문제가 있다고 예외를 표시하지 않지만 나중에 해당 요청을 수행할 수 있다고 전달받을 수 있다.

쇼핑 사이트에서 개인의 선호도에 따라 물건을 추천해주는데, 선호도 서비스가 고장 난다면
폴백 처리를 이용해 일반적인 선호도에 따라 물건을 추천해주는 경우를 예로 들 수 있다.



### 5.1.4 벌크헤드

원격 자원에 대한 호출을 자원별 스레드 풀로 분리하므로 특정 원격 자원의 호출이 느려져
전체 애플리케이션이 다운될 수 있는 위험을 줄일 수 있다.

스레드 풀은 서비스르 위한 벌크헤드 (격벽) 역할을 한다.
각 원격 자우너은 분리되어 스레드 풀에 할당된다.
한 서비스가 느리게 반응한다면 해당 서비스 호출을 위한 스레드 풀은 포화되어 요청을 처리하지 못하겠지만
다른 스레드 풀에 할당된 다른 서비스 호출은 포화되지 않는다.



## 5.2 클라이언트 회복성이 중요한 이유

가상의 서비스를 가정해 보자

애플리케이션 A,B는 서비스 A를 이용하고 있고, 애플리케이션 C는 서비스 C를 이용하고있다.
클라이언트가 애플리케이션의 특정 기능을 요청하였다.
해당 기능이 처리되는 흐름은 다음과 같다.

1. 서비스 A는 자신의 데이터베이스에서 데이터를 검색한다.

2. 서비스 A는 기능을 수행하기 위한 추가적인 작업 수행을 위해 서비스 B를 호출한다.

3. 서비스 B는 자신의 데이터베이스에서 데이터를 검색한다.

4. 서비스 B는 데이터를 쓰기 위해 공유 파일 시스템과 연결되어 있는 서비스 C를 호출한다.

5. 서비스 C는 연결된 공유 파일 시스템에 데이터를 쓴다.

   

이때 만약 서비스 C에 문제가 생기면 어떻게 될까?

개발자들은 데이터베이스에 대한 쓰기와 서비스에 대한 읽기가 동일한 트랜잭션 안에서 발생하도록
코드를 작성했다.

서비스 C가 느리게 실행되기 시작하면 서비스 C에 대한 요청이 스레드 풀에 쌓이는 것 뿐만 아니라,
서비스 컨테이너의 커넥션 풀에 있는 데이터베이스 커넥션 개수도 고갈된다.
서비스 C에 대한 호출이 완료되지 않아 커넥션을 사용 중이기 때문이다.

서비스 A는 서비스 C 때문에 느려진 서비스 B를 호출하므로 자워니 부족해지기 시작한다.
결국 세 애플리케이션 모두 요청이 완료될 때까지 기다리는 동안 자원이 고갈되어 응답하지 않는다.

회로 차단기 패턴이 분산 자원을 호출하는 모든 곳에 구현 되었다면 이 시나리오를 피할 수 있다.
서비스 C 호출에 회로 차단기를 구현했다면, C에 대한 특정 호출을 감지하는 회로 차단기가
C가 제대로 수행되지 않는다면 스레드를 소진하지 않도록 빠르게 실패했을 것이다.

서비스 B가 다수의 엔드포인트를 노출한다면 서비스 C 호출과 관련된 엔드포인트만 영향을 받을 것이다.
서비스 B의 나머지 기능은 온전하므로 사용자 요청을 수행할 수 있다.

회로 차단기를 사용한다면
서비스 B는 직접 서비스 C를 호출하지 않고 회로 차단기에 실제 호출을 위임한다.
회로 차단기는 그 호출을 스레드로 감싼다.
호출을 스레드로 감싸면 클라이언트는 호출 완료를 직접 기다리지 않는 대신
회로 차단기가 스레드를 모니터링하고 스레드가 너무 오래 수행되면 호출을 중단한다.

특정 시간 동안 특정 서비스 에러가 기대 이상 발생하면 회로 차단기는 회로를 '차단' 한다.

**회로를 차단하면 발생하는 일**

1. 서비스 B는 회로 차단기가 타임아웃하기 전에 문제가 있다는 것을 즉시 안다.
2. 서비스 B는 완전히 실패하거나 대체 코드 (폴백) 사용하는 조치를 취하는 것 중에서 선택한다.
3. 회로 차단기가 차단된 동안 서비스 B는 서비스 C를 호출하지 못하므로 서비스 C에
   복구할 수 있는 여유가 생긴다.
   이 기회를 이용해 서비스 C는 숨돌릴 틈을 갖고 서비스 저하로 발생되는 연쇄 장애를 막을 수 있다.
4. 회로 차단기는 저하된 서비스를 간헐적으로 호출하고, 호출이 연속적으로 충분히 성공하면
   회로 차단기를 재설정한다.



**회로 차단 패턴이 제공하는 핵심 기능**

1. **빠른 실패** (fail fast)

   원격 서비스가 저하를 겪으면 애플리케이션은 빨리 실패함으로써 애플리케이션 전체를 다운시킬 수 있는
   자원 고갈 이슈를 방지한다.
   대부분 장애 상황에서 완전히 다운되는 것보다 부분적으로 다운되는 것이 더 낫다.

2. **원만한 실패** (fail gracefully)

   회로 차단기 패턴으로 원만하게 실패하거나 사용 의도로 수행하는 대체 메커니즘을 찾을 수 있다.
   예를 들어 특정 데이터 소스 조회를 시도할 때 데이터 소스의 서비스 저하가 발생한다면.
   개발자는 도른 소스 위치에서 해당 데이터를 조회하게 만들 수 있다.

3. **원활한 회복** (recover seamlessly)

   회로 차단기 패턴이 중개자 역할을 한다면
   회로 차단기는 요청 자원이 온라인 상태인지 주기적으로 확인하고,
   사람의 개입 없이 자원 접근을 다시 허용할 수 있다.



수백 개의 서비스를 보유한 대규모 클라우드 기반 애플리케이션에서 원활하게 회복하는 것은 매우 중요한 일이다.
서비스를 복구하는 데 필요한 시간을 대폭 줄이고, 직접적으로 서비스 복구에 개입하면서
(고장 난 서비스의 재시작 등) 더 큰 문제를 초래할 위험을 상당히 낮출 수 있기 때문이다.



## 5.10 요약

- 마이크로서비스에 기반을 둔 애플리케이션처럼 고도로 분산된 애플리케이션을 설계할 때는
  클라이언트 회복성이 고려되어야 한다.
- 심각한 서비스 장애 (예를 들어 서버 비정상 종료) 는 탐지하고 처리하기 쉽다.
- 성능이 나쁜 서비스 하나가 호출을 완료할 때까지 호출 클라이언트를 대기시키므로
  연쇄적인 자원 고갈을 유발한다.
- 세 가지 핵심적인 클라이언트 회복성 패턴은 회로 차단기와 폴백, 벌크헤드 패턴이다.
- 회로 차단기 패턴은 느리게 실행되고 성능 저하된 시스템 호출을 종료해 빨리 실패시키고
  자원 고갈을 방지한다.
- 폴백 패턴을 사용하면 개발자가 원격 서비스 호출이 실패하거나 호출에 대한 회로 차단기가
  실패할 때 대체할 코드 경로를 정의할 수 있다.
- 벌크헤드 패턴은 원격 호출을 서로 격리하고 원격 서비스 호출을 자체 스레드 풀로 분리한다.
  일련의 서비스 호출이 실패할 떄 애플리케이션 컨테이너의 모든 자원이 고갈되어서는 안 된다.
- 스프링 클라우드와 넷플릭스 히스트릭스 라이브러리는 회로 차단기와 폴백, 벌크헤드 패턴에 대한
  구현을 제공한다.
- 히스트릭스 라이브러리는 구성 기능이 뛰어나며, 애플리케이션 전역과 클래스,
  스레드 풀 레벨로 설정할 수 있다.
- 히스트릭스는 `THREAD` 와 `SEMAPHORE` 격리 모델을 지원한다.
- 히스트릭스의 기본 격리 모델인 `THREAD` 모델은 히스트릭스로 보호된 호출을 완벽히 격리해서
  부모 스레드 컨텍스트를 히스트릭스가 관리하는 스레드에 전파하지 않는다.
- 히스트릭스의 또 다른 격리 모델인 `SEMAPHORE` 모델은 히스트릭스 호출을 위해
  별도의 스레드를사용하지 않는다.
  이 모델은 더 효율적이지만 히스트릭스가 호출을 중단할 때 서비스가 예상하지 않은 동작도 유발할 수 있다.
- 히스트릭스를 사용하면 사용자가 정의한 `HystrixConcurrencyStrategy`를 구현해
  부모 스레드 컨텍스트를 히스트릭스가 관리하는 스레드에 주입할 수 있다.



# 6장. 스프링 클라우드와 주울로 서비스 라우팅

마이크로서비스 같은 분산형 아키텍처에서는 여러 서비스 호출 사이에서 발생하는 보안과 로깅,
사용자 추적 등 주요 행위를 확인행 할 시점이 온다.
개발팀은 이 기능을 모든 서비스에 일관되게 적용하고 싶을 것이다.
공통 라이브러리나 프레임워크를 사용해 서비스마다 이러한 기능을 직접 구축할 수 있지만
다음 세 가지를 염두에 두어야 한다.

1. 구축 중인 각 서비스에 이러한 기능을 일관되게 구현하기 어렵다.
   제품 기능 개발에 정신이 없어 서비스 로깅과 추적 기능 구현을 잊기 쉽다.
2. 이러한 기능을 적절하게 구현하기 어렵다.
   마이크로서비스에 대한 보안 기능들을 구현 중인 각 서비스에 설정하고 구성하기 어려울 수 있다.
   보안과 같은 횡단 관심사 (cross-cutting concerns) 를 각 개발팀이 담당하면 제대로 구현되지 않거나
   누락할 가능성이 높다.
3. 서비스 간 복잡한 의존성을 만든다.
   전체 서비스가 공유하는 공통 프레임워크에 더 많은 기능을 추가할수록 서비스의 재컴파일과 재배포 없이
   공통 코드의 동작 변경이나 추가를 하는 일이 더 어려워진다.
   공유 라이브러리의 핵심 기능 업그레이드가 갑자기 수개월이 걸리는 마이그레이션 과정이 될 수 있다.



이 문제를 해결하려면 특정 서비스에서 이러한 횡단 관심사들을 추상화하고 독립적인 위치에서
애플리케이션의 모든 마이크로서비스 호출에 대한 필터와 라우터 역할을 해야 한다.
이러한 횡단 관심사를 **서비스 게이트웨이** (service gateway)라고 한다.
서비스 클라이언트가 서비스를 직접 호출하지 않고 단일한 정책 시행 지점 (PEP, Policy Enforcement Point)
역할을 하는 서비스 게이트웨이로 모든 호출을 경유시켜 최종 목적지로 라우팅 한다.



## 6.1 서비스 게이트웨이란?

서비스 게이트웨이는 서비스 클라이언트와 호출될 서비스 사이에서 중개 역할으 한다.
서비스 클라이언트는 서비스 게이트웨이가 관리하는 하나의 URL을 통해 통신한다.
서비스 게이트웨이는 서비스 클라이언트 호출에서 보낸 경로를 추려 내고 서비스 클라이언트가
호출하려는 서비스를 판별한다.
서비스 게이트웨이는 애플리케이션 안의 마이크로서비스 호출로 유입되는 모든 트래픽에 대해
게이트키퍼 역할을 한다.
서비스 게이트웨이가 구축되면 서비스 클라이언트는 개별 서비스의 URL을 직접 호출하지 않고
서비스 게이트웨이로 모든 호출을 보낸다.

![서비스 게이트웨이](https://github.com/devMuscle/TIL/blob/main/images/README/%EC%84%9C%EB%B9%84%EC%8A%A4%20%EA%B2%8C%EC%9D%B4%ED%8A%B8%EC%9B%A8%EC%9D%B4.png)



서비스 게이트웨이는 클라이언트가 각 서비스에 보내는 모든 호출 사이에 위치하므로 게이트웨이는
서비스 호출에 대한 **중앙 집중식 정책 시행 지점** 역할도 한다.
중앙 집중식 PEP를 사용한다는 것은 각 개발팀이 이러한 관심사를 구현하지 않고도
서비스의 횡단 관심사를 단일 지점에서 구현할 수 있다는 것을 의미한다.

**서비스 게이트웨이에서 구현할 수 있는 횡단 관심사 예시**

- **정적 라우팅** (static routing)

  서비스 게이트웨이는 단일 서비스 URL과 API 경로로 모든 서비스를 호출하게 한다.
  개발자는 모든 서비스에 대해 하나의 서비스 엔드포인트만 알면 되므로 개발이 간단해진다.

- **동적 라우팅** (dynamic routing)

  서비스 게이트웨이는 유입되는 서비스 요청을 조사하고 요청 데이터를 기반으로 서비스 호출자
  대상에 따라 지능형 라우팅을 수행할 수 있다.
  예를 들어 베타 프로그램에 참여하는 고객의 서비스 호출은 모두 다른 코드 버전이 수행되는
  특정 서비스 클러스터로 라우팅 될 수 있다.

- **인증** (authentication) **과 인가** (authorization) 

  모든 서비스 호출은 서비스 게이트웨이로 라우팅되므로 서비스 게이트웨이는 서비스 호출자가
  자신을 인증하고 서비스를 호출할 권한 여부를 확인할 수 잇는 최적의 장소다.

- **측정 지표 수집** (metric collection) **과 로깅** (logging)

  서비스 호출이 서비스 게이트웨이를 통과할 때 측정 지표와 로그 정보를 수집할 수 있다.
  규격화된 로깅을 보장하기 위해 사용자 요청에서 주요 정보가 누락되지 않았는지 확인하는 데도 사용된다.
  각 서비스에서 측정 지표를 수집할 필요가 없다는 것이 아니라 서비스 게이트웨이를 사용하면
  서비스가 호출된 횟수와 응답 시간처럼 많은 기본 측정 지표를 한곳에서 수집할 수 있다는 의미다.



**서비스 게이트웨이가 단일 장애지점이나 잠재적 병목 지점인가?**

집중화된 로드 밸런서가 단일 장애 지점과 서비스의 병목점이 될 가능성이 있다고 했다.
서비스 게이트웨이를 올바르게 구현하지 않으면 동일한 위험 부담임 있다.
서비스 게이트웨이를 구현할때는 다음을 염두에 두자

로드 밸런서는 각 서비스 그룹 앞에 있을 때 여전히 유용하다.
이때 여러 서비스 게이트웨이 인스턴스 앞에 로드 밸런서를 두는 것은 적절한 설계이며,
서비스 게이트웨이를 확장할 수 있다.
모든 서비스 인스턴스 앞에 로드 밸런서를 두는 것은 병목점이 될 수 있어 좋은 생각은 아니다.

작성하는 서비스 게이트웨이 코드를 무상태(stateless)로 유지하자.
서비스 게이트웨이의 정보를 메모리에 저장하지 말자.
주의하지 않으면 게이트웨이의 확장성을 제한하고 모든 서비스 게이트웨이 인스턴스에
데이터가 복제되도록 해야한다.

작성하는 서비스 게이트웨이 코드를 가볍게 유지하자.
서비스 게이트웨이는 서비스 호출에 대한 '병목점' 이다.
여러 데이터베이스 호출이 포함된 복잡한 코드는 서비스 게이트웨이에서 추적하기 힘든 성능 문제의 원인이 된다.



## 6.2 스프링 클라우드와 넷플릭스 주울 소개

스프링 클라우드는 넷플릭스의 오픈 소스 프로젝트인 주울을 통합한다.
주울(Zuul)은 스프링 클라우드 애너테이션으로 설정하고, 사용하기 매우 쉬운 서비스 게이트웨이다.

**주울이 제공하는 기능**

- **애플리케이션의 모든 서비스 경로를 단일 URL로 매핑**

  주울의 매핑이 단일 URL로만 제한되는 것은 아니다.
  주울에서는 여러 경로 항목읠 정의해 경로 매핑을 매우 세분화할 수 있다.
  (각 서비스 엔드포인트는 고유한 경로로 매핑된다)
  하지만 주울의 가장 일반적인 사용 사례는 모든 서비스 호출이 통과하는 단일 진입점을 구축하는 것이다.

- **게이트웨이로 유입되는 요청을 검사하고 대응할 수 있는 필터 작성**

  이러한 필터를 사용하면 코드에 정책 시행 지점(PEP)을 주입해서 모든 서비스 호출에서
  광범위한 작업을 일관된 방식으로 수행할 수 있다.



### 6.2.3 유레카와 통신하는 주울 구성

주울 프록시 서버는 기본적으로 스프링 제품과 동일하도록 설계되었다.
따라서 주울은 자동으로 유레카를 사용해 서비스 ID로 서비스를 찾은 후 넷플릭스 리본으로
주울 내부에서 요청에 대한 클라이언트 측 부하 분산을 수행한다.



## 6.3 주울에서 경로 구성

주울은 본래 리버스 프록시다.
리버스 프록시는 자원에 접근하려는 클라이언트와 자원 사이에 위치한 중개 서버다.
클라이언트는 프록시가 아닌 다른 서버와 통신하는 것조차 알 수 없고, 리버스 프록시는
클라이언트의 요청을 받은 후 클라이언트를 대신해 원격 자원을 호츨한다.

마이크로서비스 아키텍처에서 주울은 클라이언트에서 받은 마이크로서비스 호출을
하위 서비스(down stream)에 전달한다.
서비스 클라이언트는 주울과 통신한다고 생각한다.
주울이 하위 클라이언트와 통신하려면 유입되는 호출을 어떻게 하위 경로로 **매핑**할지 알아야 한다.



### 6.3.1 서비스 디스커버리를 이용한 자동 경로 매핑

주울은 `zuulsvr/src/main/resources/application.yml` 에 경로를 정의해서 모든 경로를 매핑한다.
또 특별한 구성 없이도 서비스 ID를 기반으로 요청을 자동 라우팅한다.
경로를 지정하지 않으면 호출되는 서비스의 유레카 서비스 ID를 사용해 하위 서비스 인스턴스에 매핑한다.

유레카와 함께 주울을 사용하면 호출할 수 있는 단일 엔드포인트를 제공할 뿐만 아니라
주울 수정 없이도 인스턴스를 추가하고 제거할 수 있는 장점이 있다.
예를 들어 유레카에 새로운 서비스를 추가하면 주울은 자동으로 이 서비스 인스턴스에 라우팅하는데,
서비스 엔드포인트의 실제 물리적 위치를 유레카와 소통하고 있어 가능하다.



## 6.3.2 서비스 디스커버리를 이용한 수동 경로 매핑

주울을 사용하면 서비스의 유레카 서비스 ID로 자동 생성된 경로에 의존하지 않고 명시적으로
매핑 경로를 정의할 수 있기 때문에 더욱 세분화할 수 있다.
주울에서 조직 서비스의 기본 경로인 `/organizationservice/v1/organizations/{organization-id}`를
사용해 접근하지 않고 조직 이름을 줄여 경로를 단순화한다고 가정하자.
이 작업은 `zzulsvr/src/main/resources/application.yml`에서 경로 매핑을 수동의로 정의하면 된다.

```yaml
zzul :
	ignored-service : 'organizationservice'
	routes :
		organizationservice : /organization/**
```

이 구성 항목을 추가하면 `/organization/v1/organizations/{organization-id}` 경로로
조직 서비스에 엑세스할 수 있다.

주울은 유레카 서비스 ID를 기반으로 서비스를 제공하는 자동 경로 매핑만 사용할 때
실행 중인 서비스 인스턴스가 없다면 서비스 경로를 노출하지 않는다.
하지만 수동으로 서비스 디스커버리 ID 경로를 매핑한다면 유레카에 등록된 서비스 인스턴스가 없더라도
주울은 그 경로를 계속 표시한다. 존재하지 않는 서비스 경로를 호출하면 주울은 500 에러를 반환한다.

주울 구성에서 `prefix` 프로퍼티를 사용해 서비스 호출앞에 레이블을 붙일 수 있다.
`/api` 같은 레이블을 붙여 API 와 콘텐츠 경로를 구별할 수 있다.



### 6.3.3 정적 URL을 이용한 수동 경로 매핑

유레카로 관리하지 않는 서비스를 라우팅하는 데 주울으 사용할 수 있다.
주울은 고정 URL에 직접 라우팅하도록 설정할 수 있다.
예를 들어 파이썬으로 된 라이선싱 서비스에 프록시를 할 수 있는 것이다.

```yaml
zuul :
	routes :
		licensestatic: # 주울은 키 이름으로 서비스를 내부적으로 식별한다
			path : /licensestatic/** ## 라이선싱 서비스에 대한 정적 경로다
			url : http://licenseservice-static:8081
            ## 유레카를 통하지 않고 주울이 직접 호출할 라이선싱 서비스의 정적 인스턴스를 설정한다.
```



**JVM 기반이 아닌 서비스 다루기**

경로를 정적으로 매핑하고 리본에서 유레카를 비활성화할 때 문제는 주울 서비스 게이트웨이로 실행되는
모든 서비스에 대해 리본을 지원할 수 없다는 것이다.
리본을 사용할 수 없기에 서비스 위치를 확인할 필요가 있을 때마다 유레카를 호출해야 하므로
유레카 서버가 더 많은 부하를 받게 된다는 것을 의미한다.

JVM 기반이 아닌 애플리케이션은 경로를 처리할 별도의 주울 서버를 설정할 수 있지만
스프링 클라우드의 '사이드카(sidecar)' 인스턴스를 설정하면 더 낫다.
사이드카는 JVM 기반이 아닌 서비스를 유레카 인스턴스에 등록한 후 주울로 프록시할 수 있다.



### 6.3.5 주울과 서비스 타임 아웃

주울은 넷플릭스의 히스트릭스의 리본 라이버리를 사용해 오래 수행되는 서비스 호출이
서비스 게이트웨이의 성능에 영향을 미치지 않도록 한다.
기본적으로 주울의 요청을 처리하는 데 1초 이상 걸리는 모든 호출을 종료하고 HTTP 500 에러를 반환한다.
(히스트릭스 기본 동작)

주울로 실행 중인 모든 서비스에 대해 히스트릭스 타임 아웃을 설정하려면
`hystrix.command.default.execution.isolation.thread.timeoutnMilliseconds` 프로퍼티로 가능하다.
또한 프로퍼티의 `default` 부분을 다른 서비스로 특정하면 해당 서비스에 대한 타임아웃만 설정 가능하다.

5초 이상의 타임아웃 구성은 히스트릭스와 리본 모두 설정을 해야한다.



## 6.4 주울의 진정한 힘! 필터

주울은 게이트웨이를 통과하는 모든 서비스 호출에 대해 사용자 정의 로직을 작성할 수 있다.
이러한 사용자 정의 로직 대부분은 모든 서비스에 대한 보안과 로깅 및 추적처럼 일관된
애플리케이션 정책을 시행하는 데 사용된다.

이러한 애플리케이션 정책을 구현하기 위해 애플리케이션의 각 서비스를 수정하지 않고
모든 서비스에 적용하기 원하기 때문에 이 정책들을 **횡단 관심사**로 간주한다.

주울 필터를 사용하면 주울로 라우팅되는 모든 서비스에 대해 횡단 관심사를 구현할 수 있다.

**주울이 지원하는 세 가지 필터 타입**

- **사전 필터** (pre-filter)

  주울에서 모표 대상에 대한 실제 요청이 발생하기 전에 호출된다.
  서비스의 일관된 메시지 형식 (주요 HTTP 헤더의 포함 여부 라던지)을 확인하는 작업을 수행하거나 서비스를 이용하는 사용자가 인증(본인 증명) 및 인가(수행 권한 부여) 되었는지 확인하는 게이트키퍼 역할을 한다.

- **사후 필터** (post filter)

  대상 서비스를 호출하고 응답을 클라이언트로 전송한 후 호출된다.
  대상 서비스의 응답을 로깅하거나 에러 처리, 민감한 정보에 대한 응답을 감시하는 목적으로 구현

- **경로 필터** (route filter)

  대상 서비스가 호출되기 전에 호출을 가로채는 데 사용된다.
  일정 수준의 동적 라우팅 필요 여부를 결정하는 데 사용된다.
  동일 서비스의 다른 두 버전을 라우팅 할 수 있는 경로 단위 필터를 사용해
  작은 호출 비율만 새 버전의 서비스로 라우팅 할 수 있다.
  이렇게 하면 모든 사용자가 새로운 서비스를 이용하지 않고도 소수 사용자에게 새로운 기능을 노출할 수 있다.



**호출이 필터를 통해 처리되는 흐름**

1. 요청이 주울 게이트웨이에 유입되면 정해진 사전 필터가 호출된다.
   사전 필터는 HTTP 요청이 실제 서비스에 도달하기 전에 요청을 검사하고 수정한다.
   사전 필터는 사용자를 다른 엔드포인트나 서비스로 향하게 할 수 없다.
2. 주울은 유입된 요청에 대해 사전 필터를 실행한 후 정해진 경로 필터를 실행한다.
   경로 필터는 서비스가 향하는 목적지를 변경할 수 있다.
3. 경로 필터는 주울 서버가 전송하도록 구성된 경로가 아닌 다른 경로로 서비스 호출을
   리다이렉션하는 것도 가능하다.
   하지만 주울의 경로 필터는 HTTP 리다이렉션 대신 유입된 HTTP 요청을 종료한 후
   원래 호출자를 대신해 그 경로를 호출한다.
   이것은 경로 필터가 동적 경로 호출을 완전히 소유해야 하므로 HTTP 리다이렉션 할 수 없다는 것을 의미한다.
4. 경로 필터가 호출자를 새로운 경로로 동적 리다이렉션하지 않는다면 주울 서버는 원래 대상 서비스의
   경로를 보낸다.
5. 호출되었다면 주울의 사후 필터가 호출된다.
   사후 필터는 호출된 서비스의 응답을 검사하고 수정할 수 있다.



## 6.8 요약

- 마이크로서비스는 서비스 게이트웨이 구축을 단순화한다
- 주울 서비스는 넷플릭스 유레카 서버와 통합되고 유레카에 등록된 서비스를 자동으로 주울 경로에 매핑한다
- 주울을 관리하는 모든 경로 앞에 `/api` 같은 prefix 를 서비스 경로에 쉽게 추가할 수 있다
- 주울을 사용하면 수동으로 경로 매핑을 정의할 수 있다.
  이러한 경로 매핑은 애플리케이션 구성 파일에 정의한다.
- 스프링 클라우드 컨피그 서버를 사용해 주울 서버를 재시작하지 않고 경로 매핑을
  동적으로 다시 로드할 수 있다.
- 주울의 히스트릭스와 리본 타임아웃을 전체 및 개별 서비스 수준으로 사용자 정의할 수 있다.
- 주울 필터로 사용자 정의 비즈니스 로직을 구현할 수 있다.
  주울은 3개의 주울 필터인 사전 필터와 사후 필터, 경로 필터를 제공한다
- 주울의 사전 필터는 상관관계 ID를 생성해 주울로 연결되는 모든 서비스에 주입한다
- 주울의 사후 필터는 서비스 클라이언트에 대한 모든 HTTP 서비스 응답에 상관관계 ID를 삽입한다
- 사용자 정의된 주울의 경로 필터는 유레카 서비스 ID에 기반을 둔 동적 라우팅을 수행해
  동일 서비스의 다른 버전에 대해 A/B 테스팅을 수행할 수 있다



# 7장. 마이크로서비스의 보안

안전한 애플리케이션은 다음과 같은 여러 보호 계층을 포함한다

- 사용자를 적절히 통제해 사용자 본인 여부를 확인하고 수행하려는 작업에 대한 권한 여부를 검증할 수 있다

- 서비스가 실행되는 인프라스트럭처를 꾸준히 패치하고 최신 상태로 유지해 취약점의 위험을 최소화한다

- 서비스는 명확히 정의된 포트로만 접근하고 소수의 인가된 서버만 접근할 수 있도록
  네트워크 접근을 통제한다

  

## 7.1 OAuth2 소개

OAuth2는 토큰 기반의 보안 인증과 인가 프레임워크로 다음 4개의 컴포넌트로 구성된다

1. **보호 자원** (protected resource)

   보호하려는 자원 (여기서는 마이크로서비스)이며 적절한 권한을 부여받은 인증된 사용자만 엑세스 할 수 있다.

2. **자원 소유자** (resource owner)

   서비스를 호출할 수 있는 애플리케이션 및 서비스에 접근할 수 잇는 사용자, 그리고 서비스에서
   수행할 수 있는 작업을 정의한다.
   자원 소유자가 등록한 애플리케이션은 식별 가능한 애플리케이션 이름과 시크릿 키를 받는다.
   애플리케이션 이름과 시크릿 키는 OAuth2 토큰을 인증할 때 전달되는 자격 증명의 일부다.

3. **애플리케이션** 

   사용자를 대신해 서비스를 호출할 애플리케이션이다.
   즉, 사용자는 서비스를 직접 호출하지 않는 대신 애플리케이션에 의존해 작업을 수행한다.

4. **OAuth2 인증 서버** (OAuth2 authentication server)

   애플리케이션과 소비되는 서비스 사이의 중개자다.
   OAuth2 서버를 사용하면 애플리케이션이 사용자 대신 호출하는 모든 서비스에
   사용자의 자격 증명(credential)을 전달하지 않고도 사용자 자신을 인증할 수 있다.

4개의 컴포넌트는 서로 통신하며 사용자를 인증한다.
사용자는 자격 증명만 제시하면 된다.
인증에 성공하면 서비스 간 전달되는 인증 토큰을 발급 받는다.
OAuth2는 토큰 기반의 보안 프레임워크이기 때문에 사용자는 자원에 접근하려는 애플리케이션을 통해
자격 증명을 제시하고 OAUth2 서버에서 인증한다.
사용자의 자격 증명이 유효하면 OAuth2 서버는 사용자 애플리케이션이 이용하는 서비스가 보호 자원
(마이크로서비스)에 접근하려고 시도할 대마다 제시할 토큰을 제공한다.

![OAuth2](https://github.com/devMuscle/TIL/blob/main/images/README/OAuth2.png)

보호 자원은 OAuth2 서버에 접속해 토큰 유효성을 확인하고 사용자가 지정한 역할을 조회할 수 있다.
역할은 연관된 사용자를 함께 그룹으로 묶고 **사용자 그룹**이 액세스 할 수 있는 자원을 정의한다.

OAuth2를 사용하면 그랜트(grants) 라는 인증 체계를 이용해 다양한 시나리오에서
REST 기반 서비스를 보호할 수 있다.
OAuth2 명세에는 다음 네 가지 그랜트 타입이 있다.

- 패스워드 (password)
- 클라이언트 자격 증명 (client credential)
- 인가 코드 (authorization code)
- 암시적 (implicit)	



# 8장. 스프링 클라우드 스트림을 사용한 이벤트 기반 아키텍처

메시지를 사용해 상태 변화를 표현하는 이벤트로 통신하는 개념을 이벤트 기반 아키텍처 (EDA, Event Driven Architecture) 또는 메시지 기반 아키텍처 (MDA, MEssage Driven Architecture)라고 한다.
EDA 기반의 접근 방식을 사용하면 특정 라이브러리나 서비스에 밀접하게 결합하지 않고
변화에 대응할 수 있는 높은 수준으로 분리된 시스템을 구축할 수 있다.
EDA가 마이크로서비스와 합쳐지면 애플리케이션이 발송하는 이벤트(메시지) 스트림을
서비스가 수신하는 것만으로도 새로운 기능을 애플리케이션에 신속하게 추가할 수 있다.

스프링 클라우드 프로젝트의 하위 프로젝트인 스프링 클라우드 스트림을 사용하면
메시지 기반 솔루션을 손쉽게 구축할 수 있다.
스프링 클라우드 스트림은 메시지 발행과 소비를 쉽게 구현하고 하부 메시징 플랫폼과 연관된 세부 구현에서
서비스를 분리할 수 있게 도와준다.



## 8.1 메시지와 EDA, 마이크로서비스의 사례

마이크로서비스 기반 애플리케이션을 구축하는 데 메시징이 중요한 이유를 예시로 보자

서비스 A와 서비스 B가 있다.
서비스 A의 데이터를 조회하는 서비스 B의 호출이 상당히 오래 걸린다는 사실알게 됐다.
서비스 A의 데이터의 사용 패턴을 살펴보면 데이터의 변경이 드물고 Primary Key로 데이터를 읽어 온다.
데이터베이스 엑세스 비용을 들이지 않고 데이터의 읽기를 캐싱할 수 있다면
응답 시간을 크게 향상 시킬 수 있을 것이다.

캐싱 솔루션의 구현을 살펴보면 세 가지 핵심 요구 사항을 발견할 수 있다.

1. **캐싱된 데이터는 서비스 B의 모든 인스턴스에 일관성이 있어야 한다.**

   어떤 인스턴스에 접근하더라도 동일한 서비스A의 데이터 읽기가 보장되어야 하므로
   서비스B 안에 서비스 A의 데이터를 로컬캐싱해서는 안 된다는 것을 의미한다.

2. **서비스B를 호스팅하는 컨테이너 메모리에 서비스 A의 데이터를 캐싱해서는 안 된다.**

   서비스를 호스팅하는 런타임 컨테이너는 종종 크기 제약이 있으며 다양항 액세스 패턴으로
   데이터를 액세스한다.
   로컬 캐시는 클러스터 내 다른 모든 서비스와 동기화를 보장해야 하므로 복잡성도 증가한다.

3. **업데이트나 삭제 연산으로 서비스 A의 레코드가 변경될 때**
   **서비스 B는 서비스 A의상태 변화를 인식해야 한다.**
   이것으로 서비스 B는 캐싱된 특정 서비스A의 데이터를 무효화하고 삭제할 수 있다.



이러한 요구 사항을 구현하는 데 두 가지 접근법이 있다.

1. **동기식 요청-응답 모델 사용**

   서비스 A가 변경되면 서비스 B와 서비스 A는 REST 엔드포인트를 이용해 서로 통신한다. 

2. **서비스A가 자신이 변경되었음을 알리는 비동기 이벤트 (메시지)를 발송**

   서비스 A는 메시지를 발행하고 서비스 A의 레코드가 업데이트되거나 삭제되었다는 메시지를
   큐에 발행(publish) 한다.
   서비스 B는 중개자에게서 수신하며, 서비스 A의 이벤트가 발생했는지 확인하고
   서비스 A의 데이터를 캐시에서 삭제한다.



### 8.1.1 동기식 요청-응답 방식으로 상태 변화 전달

![동기싱 요청-응답 모델](https://github.com/devMuscle/TIL/blob/main/images/README/%EB%8F%99%EA%B8%B0%EC%8B%B1%20%EC%9A%94%EC%B2%AD-%EC%9D%91%EB%8B%B5%20%EB%AA%A8%EB%8D%B8.png)



사용자가 서비스A를 호출할 때 서비스 A는 서비스 B의 데이터도 조회해야 한다.
서비스 A는 먼저 레디스 클러스터에서 원하는 서비스B의 데이터를 ID로 조회할 수 있는지 확인한다.
레디스에 없다면 REST 기반의 엔드포인트를 사용해 서비스 B를 호출한 후,
전달받은 데이터를 사용자에게 반환하기 전에 레디스로 저장한다.
누군가 서비스 B의 REST 엔드포인트를 사용해 서비스 B의 데이터를 변경하거나 삭제하면
서비스 B는 서비스 A의 캐시 데이터를 무효화하기 위해 서비스 A의 엔드포인트를 호출한다.
서비스 B가 레디스 캐시를 무효화하라고 다시 서비스 A를 호출할 때 적어도 3가지 문제를 발견할 수 있다.

1. 서비스 A와 서비스 B는 강하게 결합되어 있다.
2. 결합은 두 서비스 사이에 깨지기 쉬운 성질(brittleness)이 생긴다.
   예를 들어, 캐시 변경을 무효화 하는 서비스 A의 엔드포인트가 변경되면 서비스 B도 따라서 변경되어야 한다.
3. 서비스 B의 데이터 변경 사실을 인식하도록 다른 서비스를 호출하는 서비스 B의 코드를 수정하지 않고
   서비스 B의 데이터의 소비자를 추가할 수 없기 때문에 이 방식은 유연하지 않다.
   (새로운 서비스 C가 서비스 B의 데이터를 사용해서 캐싱한다고 하면 서비스 B에서는 데이터가 변경되면
   서비스 C에게도 그 사실을 알리는 로직을 추가해야 한다.)



**서비스 간 강한 결합**

서비스 A는 데이터를 조회하기 위해 항상 서비스B에 의존성을 갖는다.
하지만 서비스 B의 레코드가 업데이트 되거나 삭제될 때마다 서비스 B가 다시 서비스 A와 직접 통신함으로써
서비스 B에서 서비스 A로 향하는 결합이 발생했다.



**쉽게 깨지는 서비스 관계**

서비스 A와 서비스 B 사이의 강한 결합은 오히려 두 서비스 사이가 쉽게 깨질 수 있는 성질을 만든다.
서비스 A가 다운되거나 느려지면 서비스 B는 서비스 A와 직접 통신하므로 영향을 받는다.
서비스 B가 서비스 A의 레디스 데이터 저장소와 직접 통신했다면,
서비스 B와 레디스 사이에 의존성이 생긴 것이다.
이렇게 되면 레디스 서버에 문제가 발생하면 두 서비스를 모두 다운시킬 수도 있다.



**조직 서비스 변경에 관심 있는 새 소비자를 추가할 때 경직성**

이 아키텍처는 유연하지 못하다는 문제가 있다.
서비스 B의 데이터의 변경에 관심 있는 다른 서비스가 추가된다면 서비스 B에서는
그 서비스 호출을 추가해야 한다.
이것은 서비스 B의 코드를 변경하고 재배포해야 한다는 것을 의미한다.
상태 변경을 통신하기 위해 동기식 요청-응답 모델을 사용하면 애플리케이션의 핵심 서비스와
다른 서비스 사이에 거미줄 모양의 의존성 패턴을 보여준다.
거미줄 중앙은 애플리케이션의 주요 장애 지점이 된다.



**또 다른 종류의 결합**
메시징이 서비스 사이에 간접 계층을 추가하지만, 여전히 메시지를 사용하는 두 서비스 간에
밀접하게 결합되게 할 수 있다.
메시지 전송 프로토콜로 JSON을 사용하는데, JSON 메시지 구조를 변경할 때 두 서비스가 동일한
메시지 타입의 여러 버전을 적절히 처리하지 못한다면 자바로 상호 변환할 떄 문제가 될 수 있다.
JSON은 버전 관리를 지원하지 않기에, 버전 관리 기능이 내장된 바이너리 프로토콜인
아파치 아브로를 사용할 수 있다.



### 8.1.2 메시징을 사용해 서비스 간 상태 변화 전달

메시징 방식을 사용하면 서비스 A와 B 사이에 큐를 삽입한다.
이 큐는 서비스 B의 데이터를 읽는 데 사용되는 것이 아니라, 서비스 B가 관리하는 데이터의 상태가 변할 때
서비스 B가 메시지를 발행하는 데 사용된다.

![메시징을 사용한 서비스 간 상태 변화 전달](https://github.com/devMuscle/TIL/blob/main/images/README/%EB%A9%94%EC%8B%9C%EC%A7%95%EC%9D%84%20%EC%82%AC%EC%9A%A9%ED%95%9C%20%EC%84%9C%EB%B9%84%EC%8A%A4%20%EA%B0%84%20%EC%83%81%ED%83%9C%20%EB%B3%80%ED%99%94%20%EC%A0%84%EB%8B%AC.png)

서비스 B의 데이터가 변경될 때마다 서비스 B는 메시지를 큐에 발행한다.
서비스 A는 메시지 큐를 모니터링하고 메시지가 들어오면 레디스 캐시의 서비스 B의 레코드를 적절히 삭제한다.
상태 전달에서 메시지 큐는 서비스간 중개자 역할을 한다.

이 방식은 다음 네 가지 이점을 제공한다.



**느슨한 결합**

마이크로서비스 애플리케이션은 수많은 작은 서비스로 분산되어 상호 작용하며 서로가 관리하는
데이터에 관심이 있다.

동기식 HTTP 응답은 라이선싱 및 조직 서비스 사이에 강한 의존성을 만든다.
이 의존성을 완전히 제거할 수는 없지만 서비스가 소유한 데이터를 직접 관리하는 엔드포인트만
노출함으로써 의존성을 최소화할 수 있다.

메시징 방식에서는 상태 변화를 전달하는 과정에서 두 서비스가 서로 알지 못하므로 결합되지 않는다.
서비스 B는 상태 변화를 발행해야 할 때 큐에 메시지를 기록하며, 서비스 A는 메시지 수신 여부만 알고
누가 메시지를 발행했는지 알 수 없다.



**내구성**

큐가 존재하므로 서비스 소비자가 다운될 때도 메시지 전달을 보장할 수 있으며,
서비스 B는 서비스 A가 가용하지 않더라도 메시지를 계속 발행할 수 있다.

메시지는 큐에 저장되고 서비스 A가 다시 가용할 때까지 유지될 것이다.
반대로 캐시와 큐 방식을 조합하면 서비스 B가 다운될 때도 서비스 B 데이터의 일부분이 캐시에 유지되므로
서비스 A가 적절히 기능을 저하시킬 수 있다.
때때로 지난 데이터라도 있는 것이 아예 없는 것보다 낫다.



**확장성**

메시지가 큐에 저장되므로 메시지 발신자는 메시지 소비자의 응답을 기다릴 필요가 없다.
발신자는 하던 일을 계속하면 된다.

큐에서 메시지를 읽어 오는 소비자가 메시지를 빠르게 처리하지 못한다면,
메시지 소비자를 더 많이 가동시켜 큐의 메시지를 신속히 처리하는 것은 큰일이 아니다.

새 마이크로서비스 인스턴스를 손쉽게 가동시키고 추가된 서비스가 큐에 보관 중인 메시지를
쉽게 처리해야 하므로 이러한 확장적 접근 방법은 마이크로서비스 모델과 잘 들어 맞는다.

이 확장성이 수평 확장의 한 예다.
큐에서 메시지를 읽어 오는 것과 관련한 전통적인 확장 메커니즘은
메시지 소비자가한 번에 처리할 수 있는 스레드 개수를 늘리는 것이다.
하지만 이 방식은 메시지 소비자가 사용할 수 있는 CPU 개수에 제한을 받는다.
마이크로서비스 모델은 메시지 소비자의 호스팅 머신을 늘려 확장하기 때문에 이러한 제약이 없다.



**유연성**

메시지 발신자는 누가 메시지를 소비할지 모른다.
즉, 원래 발신 서비스에 영향을 주지 않고 새로운 메시지 소비자를 쉽게 추가할 수 있다.

기존 서비스를 건드리지 않고 새로운 기능을 애플리케이션에 추가할 수 있기 때문에 매우 강력한 개념이다.
새로운 기능의 코드는 발행되는 이벤트를 수신해서 적절히 대응할 수 있다.



### 8.1.3 메시지 아키텍처의 단점

**메시지 처리의 의미론**

메시지를 사용하려면 메시지를 발행하고 소비하는 방법을 아는 것 이상이 필요하다.
애플리케이션이 메시지의 소비 순서를 기반으로 어떻게 동작할지와 메시지가 순서대로 처리되지 않을 때
어떤 일이 발생할지 이해해야 한다.

예를 들어, 한 고객의 모든 주문을 받은 순서대로 처리해야 한다는 엄격한 요구 사항이 있다면,
모든 메시지를 서로 독립적으로 소비하는 방식과 다르게 처리하도록 설정하고 구성해야 할 것이다.

메시징을 사용해 데이터의 상태 전이를 엄격하게 다루어야 할 때 예외가 발생하거나 순서대로 처리되지 않는
시나리오를 애플리케이션의 설계 단계에서부터 고려해야 한다는 것을 의미한다.

"메시지가 실패하면 에러 처리를 재시도할 것인가? 아니면 그냥 실패하게 놔둘 것인가? 특정 고객 메시지 중
하나가 실패할 경우 해당 고객과 관련된 향후 메시지를 어떻게 처리할 것인가?" 등 깊이 생각할 주제다.



**메시지 가시성**

마이크로서비스에서 메시지 사용은 종종 동기식 서비스 호출과 서비스 내 비동기 처리가 합쳐진 것을 의미한다.
메시지의 비동기적 특성으로 메시지가 발행되거나 소비될 때 메시지의 수신과 처리가 아주 근접한 곳에서
이루어질 필요는 없다.

웹 서비스의 호출과 메시징을 경유하는 사용자 트랜잭션을 추적하기 위해 상관관계 ID를 사용하는 것도
애플리케이션에서 발생하는 일을 이해하고 디버깅하는 데 매우 중요하다.

상관관계 ID는 사용자 트랜잭션의 시작 시점에 생성되는 고유한 숫자로 모든 서비스가 호출될 때 전달한다.
메시지가 발행되고 소비될때도 함께 전달된다.



**메시지 코레오그래피**

'메시지 가시성'에서 짐작했듯이 메시징 기반 애플리케이션은 코드가 더 이상 단순한 요청-응답 모델을 사용해
선형적으로 처리되지 않기 때문에 애플리케이션 비즈니스 로직을 추론하는 것은 더 어려워진다.

메시징 기반 애플리케이션의 디버깅은 사용자 트랜잭션이 순서가 바뀌고 다른 시점에 실행될 수 있는
다양한 서비스의 로그를 꼼꼼히 살펴보는 일이다.



## 8.5 요약

- 메시징을 사용한 비동기식 통신은 마이크로서비스 아키텍처의 중요한 부분이다.

- 애플리케이션에서 메시징을 사용하면 서비스를 확장하고 결함에 더 잘 견디게(fault-tolerant) 만들 수 있다.
- 스프링 클라우드 스트림은 간단한 애너테이션을 사용하고 하부 메시지 플랫폼별 세부 정보를 추상화해
  메시지 발행과 소비를 단순화한다.
- 스프링 클라우드 스트림의 메시지 소스는 애너테이션된 자바 메서드로
  메시지 브로커 큐에 메시지를 발행한다.
- 스프링 클라우드 스트림의 메시지 싱크는 애너테이션된 자바 메서드로 메시지 브로커에서 메시지를 수신한다.

- 레디스는 데이터베이스와 캐시로 사용될 수 있는 키-값 저장소다.



# 9장. 스프링 클라우드 슬루스와 집킨을 이용한 분산 추적

마이크로서비스는 분산되어 있기에 여러 서비스와 물리 머신, 다양한 데이터 저장소 사이에서
하나 이상의 트랜잭션을 추적하고 정확한 상황을 종합하려고 노력해야 한다.



## 9.1 스프링 클라우드 슬루스와 상관관계 ID

상관관계 ID가 있다면 모든 서비스에서 스프링 HTTP 필터를 사용자 정의해 들어오는 변수를 사용자 정의 가능한
`UserContext` 객체에 매핑한다.
`UserContext` 객체를 사용하면 상관관계 ID를 로그문에 추가했는지 확인하며, 수동으로 모든 로그 문에 추가하거나
약간의 작업으로 상관관계 ID를 직접 스프링 MDC, 즉 매핑 진단 컨텍스트 (MDC, Mapped Diagnostic Context) 에 추가할 수 있다.
또 서비스에서 나가는 호출의 HTTP 헤더에 상관관계 ID를 추가해 서비스의 모든 HTTP 호출이 상관관계 ID를 전파할 수 있게 하는
스프링 인터셉터도 작성했다.

결국 문제가 발생했을 때만 살펴볼 무언가를 위해 많은 인프라스트럭처를 만들게 되었다.

다행히 스프링 클라우드 슬루스는 이 모든 코드 인프라스트럭처와 복잡성을 관리한다.
스프링 클라우드 슬루스를 이용해 다음을 수행할 수 있다.

- 상관관계 ID가 없다면 상관관계 ID를 투명하게 생성하고 서비스 호출에 주입한다
- 서비스에서 나가는 호출에 대한 상관관계 ID 전파를 관리해 트랜잭션의 상관관계 ID가 자동으로 나간는 호출에 추가된다.
- 상관관계 정보를 스프링 MDC 로그에 추가해 생성된 상관관계 ID가 스프링부트의 기본 SL4J와 로그백 구현으로 자동적으로 로깅된다.
- 선택적으로 서비스의 추적 정보를 집킨 분산 추적 플랫폼에 전송한다.



### 9.1.1 스프링 클라우드 슬루스 추가

스프링 클라우드 슬루스 의존성을 추가하면 다음 행동을 할 수 있다

1. 서비스로 들어오는 모든 HTTP 호출을 검사하고 그 호출에서 스프링 클라우드 슬루스의 추적 정보가 존재하는지 확인한다.
   추적 정보가 있다면 마이크로서비스로 전달된추적 정보를 수집해 로깅 및 처리를 위해 서비스에 제공한다
2. 스프링 클라우드 슬루스 추적 정보를 스프링 MDC에 추가해 마이크로서비스에서 생성된 모든 로그 문이 로그에 추가된다.
3. 스프링 클라우드 추적 정보를 서비스에서 나가는 모든 HTTP 호출과 스프링 메시징 채널의 메시지에 삽입한다.



### 9.1.2 스프링 클라우드 슬루스의 추적 분석

스프링 클라우드 슬루스는 4개의 추적 정보를 각 로그에 추가할 수 있다

1. **서비스 애플리케이션 이름**

   로그를 출력하는 애플리케이션 이름이다. 기본적으로 스프링 클라우드 슬루스는 애플리케이션의 이름 (`spring.application.name`) 프로퍼티를 추적해서 기록할 이름으로 사용한다.

2. **추적 ID**

   추적 ID는 상관관계 ID와 동급 용어이며, 전체 트랜잭션에서 고유한 숫자다.

3. **스팬 ID**

   스팬 ID는 전체 트랜잭션의 일부를 나타내는 고유 ID다.
   트랜잭션에 속한 각 서비스에는 고유한 스팬 ID가 있는데, 특히 트랜잭션을 시각화하는 데 유용하다.

4. **집킨에 추적 데이터 전송 여부**

   대용량 서비스에서 생성된 추적 데이터의 양은 엄청나고 모두 가치가 있는 것은 아니다.
   스프링 클라우드 슬루스를 사용하면 트랜잭션을 집킨에 보낼 시점과 방법을 결정할 수 있다.
   스프링 클라우드 슬루스의 추적 블록 끝부분에 있는 `true/false`를 표시해 추적 정보의 집킨 전송 여부를 결정한다.



## 9.2 로그 수집과 스프링 클라우드 슬루스

대규모 마이크로서비스 환경에서 애플리케이션 기능은 세분화된 서비스로 분산되어 있고, 한 종류의 서비스에
많은 서비스 인스턴스가 존재할 수 있기 때문에 사용자 문제를 해결하기 위해 여러 서비스에서 발생하는 로그 데이터를
한곳으로 연결하는 것은 상당히 어려운 일이다.
여러 서버 사이의 문제를 디버깅하려는 개발자는 종종 다음 작업을 시도해야 한다.

- 여러 서버에 로그인하며 각 서버의 로그를 검사해야 한다.
  이 작업은 특히 문제된 서비스의 트랜잭션 양이 달라 로그를 롤오버하는 속도가 다를 때는 상당히 힘들다.
- 로그를 파싱하고 관련 로그 항목을 식별하는 자체 질의 스크립트를 작성해야 한다.
  쿼리가 모두 다를 수 있어 로그에서 데이터를 질의하는 사용자 정의 스크립트가 엄청나게 늘어날때가 많다.
- 개발자가 서버에 있는 로그를 백업해야 하므로 다운된 서비스 복구 과정을 연장해야 한다.
  서비스를 호스팅하는 서버가 완전히 고장 난다면 대개 로그는 유실된다.



더 나은 접근 방법은 로그 데이터를 인덱싱하고 검색할 수 있는 중앙 수집 지점을 만들어 전체 서비스 인스턴스의 모든 로그를
실시간 스트리밍하는 것이다.



### 9.2.5 주울로 HTTP 응답에 상관관계 ID 추가

스프링 클라우드 슬루스는 HTTP 응답 정보에 추적 ID와 스팬 ID를 추가할 수 있게 한다.
하지만 이 과정에서 클래스 3개를 작성하고 사용자 정의 스프링  빈을 2개 주입해야 한다.
더 간단한 해결책은 주울의 사후 필터를 작성해 HTTP 응답에 추적 ID를 삽입하는 것이다.

주울은 `ResponseFilter`에 `Tracer` 클래스를 자동 연결해 `ResponseFilter`안에서 추적 정보를 접근할 수 잇다.
(`Tracer` 클래스는 추적 ID와 스팬 ID 정보에 접근하는 진입점이다)



## 9.3 오픈집킨으로 분산 추적

깨끗하고 간결한 그림은 로그 100만 줄보다 나을 때가 있다.
로그를 추적하는 것보다 여러 마이크로서비스 간 트랜잭션 흐름을 시각화하는 방법을 살펴보자

분산 추적은 여러 마이크로서비스 간에 트랜잭션이 어떻게 흐르고 있는지 시각적으로 보여준다.
분산 추적 도구는 개별 마이크로서비스의 응답 시간을 대략적인 근사치로 제공하지만 APM (Application Performance Management)
패키지와는 다르다.
APM은 기본적으로 서비스의 실제 코드에서 발생한 저성능 데이터와 CPU 및 I/O 사용률처럼 응답 시간 이외의
성능 데이터도 제공할 수 있다.

집킨은 여러 서비스 호출 사이의 트랜잭션을 추적하는 분산 추적 플랫폼이다.
집킨을 사용하면 트랜잭션의 소요 시간을 그래픽으로 확인할 수 있고, 호출에 관련된 각 마이크로서비스별로
소요된 시간을 분석할 수 있다.
집킨은 마이크로서비스 아키텍처에서 성능 문제를 확인할 수 있는 매우 소중한 도구다.



### 9.3.5 집킨으로 트랜잭션 추적

집킨에서 스팬을 확인해 호출에서 추가 정보를 확인할 수 있다.

클라이언트(주울)가 서비스를 호출한 시점, 서비스가 호출을 받은 시점, 서비스가 응답한 시점의 상세 정보 등을 볼 수 있다.
이러한 유형의 정보는 네트워크 지연 문제를 탐지하고 식별하는 데 매우 중요하다.



### 9.3.7 메시징 추적 수집

스프링 클라우드 슬루스와 집킨은 HTTP 호출만 추적하는 것은 아니다.
슬루스는 서비스에 등록된 인바운드 또는 아웃바운드 메시지 채널에 대한 추적 데이터도 집킨에 전송한다.

메시징은 애플리케이션 내부에서 자체 성능 문제와 지연 시간 문제를 초래할 수 있다.
서비스는 큐에서 메시지를 신속하게 처리하지 못할 수도 있고 네트워크 지연 시간 문제가 발생할 수도 있다.

스프링 클라우드 슬루스와 집킨을 사용하면 메시지가 큐에 발행된 시점과 수신된 시점을 확인할 수 있다.
그리고 메시지가 큐에 수신되고 처리될 떄 발생하는 동작을 확인할 수 있다.



### 9.3.8 사용자 정의 스팬 추가

특정 레디스나 다른 호출에 대한 추적 정보와 타이밍 정보를 얻기 위해 사용자 정의 스팬을 추가할 수 있다.



## 9.4 요약

- 스프링 클라우드 슬루스를 사용하면 마이크로서비스 호출에 추적 정보(상관관계 ID)를 완벽하게 추가할 수 있다.
- 상관관계 ID는 여러 서비스 사이에서 로그 항목을 연결하는 데 상요ㅇ된다.
  이 ID로 한 트랜잭션에 연관된 여러 서비스에서 트랜잭션 동작을 확인할 수 있다.
- 상관관계 ID가 강력하지만, 다양한 출처에서 오는 로그를 수집하고 수집된 내용을 검색하며 질의할 수 있는 수집 플랫폼과
  상관관계 ID 개념은 짝을 이루어야 한다.
- 여러 가지 사내 구축형 로그 수집 플랫폼이 존재하지만, 클라우드 기반 서비스를 사용하면
  대규모 인프라스트럭처를 갖추지 않고도 로그를 관리할 수 있다. 애플리케이션의 로깅 용량이 증가해도 쉽게 확장할 수 있다.
- 로그 수집 플랫폼과 도커 컨테이너를 통합해 컨테이너의 표준 출력,에러로 기록되는 모든 로그 데이터를 수집한다.
- 통합된 로깅 플랫폼이 중요하지만 마이크로서비스 사이의 트랜잭션을 시각적으로 추적할 수 있는 기능도 매우 소중한 도구다.
- 집킨을 사용하면 서비스 호출이 이루어질 떄 서비스 사이에 존재하는 의존성을 볼 수 있다.
- 스프링 클라우드 슬루스는 집킨과 통합된다.
  집킨은 트랜잭션 흐름을 그래픽으로 보여주고, 사용자 트랜잭션에 연관된 마이크로서비스의 성능 특성을 이해할 수 있게 한다.
- 스프링 클라우드 슬루스는 슬루스가 활성화된 서비스에서 사용되는 HTTP 호출과 인바운드/아웃바운드 메시지 채널에 대한
  추적 데이터를 자동으로 포착한다.
- 스프링 클라우드 슬루스는 각 서비스 호출을 스팬 개념에 매핑한다.
  집킨에서 각 스팬의 성능을 볼 수 있다.
- 스프링 클라우드 슬루스와 집킨에서 스프링 기반이 아닌 자원의 성능을 파악하도록 사용자 정의 스팬을 재정의할 수 있다.



# 10장. 마이크로서비스의 배포

빌드 및 배포 파이프라인을 구축하는 것이 실제로는 마이크로서비스 아키텍처의 핵심 부분 중 하나다.

마이크로서비스 아키텍처의 주요 장점 중 하나는 마이크로서비스가 신속히 빌드하고 수정하며
실제 환경에 독립적으로 배포할 수 있는 작은 코드 단위라는 것이다.
크기가 작은 서비스는 새로운 제품 기능을 빠르게 제공할 수 있다.

여기서 속도가 핵심이다.
속도가 빠르다는 것은 새로운 기능 구현과 버그 수정, 서비스 배포 사이에 마찰이 거의 없음을 암시한다.
배포 소요시간은 며칠이 아니 몇 분이 되어야 한다.

이를 위한 코드를 빌드하고 배포하는 데 사용할 매커니즘이 필요하다

- **자동화**

  코드를 빌드할 때 빌드와 배포 프로세스에서 사람이 개입하지 않아야 한다.
  특히 하위 환경 (Dev 나 Stage)에서는 더욱 개입하지 않아야 한다.
  소프트웨어 빌드 및 머신 이미지 프로비저닝, 이후 서비스의 배포 프로세스가 모두 자동화되어야 하며
  소스 저장소에 코드를 커밋하는 동작에서 시작되어야 한다.

- **반복성**

  소프트웨어를 빌드하고 배포하는 프로세스는 반복 가능해야 동일한 작업으로 수행될 수 있다.
  프로세스의 변동성은 종종 추적하고 해결하기 어렵고, 미묘한 버그의 원인이 된다.

- **완전성**

  배포된 산출물의 결과는 서비스를 위한 '완전한' 런타임 환경을 포함하는
  완비된 가상 머신이나 컨테이너 이미지여야 한다.
  이머신 이미지의 프로비저닝은 스크립트를 통해 와전히 자동화되어야 하며
  서비스 소스 코드와 함께 소스 제어 시스템에서 관리되어야 한다.

  마이크로서비스 환경에서는 대개 이러한 책임이 운영 팀에서 서비스를 소유한 개발 팀으로 이동한다.
  마이크로서비스 개발의 핵심 사상 중 하나는 서비스에 대한 운영 책임을 완전히 개발자에게 넘기는 것이다.

- **불변성**

  서비스를 포함한 머신 이미지를 빌드하고 배포한 후에 이미지에 대한
  런타임 구성을 건드리거나 변경해서는 안 된다.
  변경이 필요하다면 소스 제어 시스템에서 관리되는 스크립트에서 구성을 변경하고
  서비스와 인프라스트럭처가 빌드 프로세스를 다시 거쳐야 한다.

  애플리케이션 구성을 컨테이너와 별도로 분리해서 관리해야 하지만 (스프링 클라우드 컨피그),
  런타임 구성 변경(가비지 컬렉션 설정, 사용 중인 스프링 프로파일)은 이미지에 환경 변수로 전달해야 한다.



## 10.3 빌드 및 배포 파이프라인 아키텍처

마이크로서비스 빌드 및 배포 파이프라인 구축과 연관된 부분과 단계

1. 개발자는 소스 코드 저장소에 코드를 커밋한다.
2. 빌드 도구는 소스 제어 저장소의 변경 여부를 모니터링하고 변경이 탐지되면 빌드를 시작한다.
3. 빌드 동안 애플리케이션에 대한 단위 테스트와 통합 테스트가 실행되고
   모두 통과하면 배포 가능한 소프트웨어 산출물이 생성된다.
4. JAR 와 WAR, EAR를 서버에서 실행하는 애플리케이션 서버에 배포할 수 있다.

![CI CD](https://github.com/devMuscle/TIL/blob/main/images/README/CI%20CD.png)

이 빌드 및 배포 파이프라인에서 CD(Continuous Delivery) (지속적 전달) 단계를 프로세스에 추가한다.

1. 개발자는 자기 서비스 코드를 소스 저장소에 커밋한다.
2. 빌드 및 배포 엔진은 소스 코드 저장소의 변경 사항을 모니터링한다.
   코드가 커밋되면 빌드 및 배포 엔진은 코드를 저장소에서 가져와 코드의 빌드 스크립트를 실행한다.
3. 빌드 및 배포 프로세스의 첫 번째 단계는 코드를 컴파일하고 단위 테스트와 통합 테스트를 실행한 후
   서비스를 실행 가능한 산출물로 컴파일하는 것이다.
   마이크로서비스가 스프링 부트로 작성되므로 빌드 프로세스는 서비스 코드와 자체 완비형 톰캣 서버를
   완전히 포함한 실행 가능한 JAR 파일을 생성한다.

4. 이 단계가 전통적인 자바 CI 빌드 프로세스와 달라지는 부분이다.
   실행 가능한 JAR 파일을 빌드한 후 마이크로서비스가 배포된 머신 이미지를 굽는다.
   이미지 굽기 단계에서 가상 머신 이미지나 컨테이너를 생성하고 서비스를 설치한다.
   가상 머신 이미지를 시작하면 서비스가 시작하고 요청을 받을 준비가 된다.
   컴파일된 JAR나 WAR를 애플리케이션과 별개로 관리하며, 애플리케이션 서버에 배포하는
   전통적 CI 빌드 프로세스와 달리 CI/CD 프로세스를 사용하면 마이크로서비스와 서비스용 런타임 엔진,
   머신 이미지 전부를 하나의 상호 의존 단위로 배포하고 그 소프트웨어를 작성한 개발 팀이 관리한다.

5. 공식적으로 새 환경에 배포하기 전에 머신 이미지를 시작해
   실행 중인 이미지에 대한 일련의 플랫폼 테스트를 수행하고 정상적으로 동작하는지 확인한다.
   플랫폼 테스트를 통과하면 머신 이미지는 새로운 환경으로 승격되어 사용할 수 있다.

6. 서비스가 새 환경으로 승격되기 전에 새로운 환경에서 플랫폼 테스트를 거쳐야 한다.
   서비스를 상위 환경으로 승격하면 하위 환경에서 사용한 것과 동일한 머신 이미지로
   시작한다는 것을 의미한다.

   완전한 머신 이미지로 배포한다.
   서버가 생성된 후 설치된 소프트웨어에 절대 변경되지 않는다.
   동일한 머신 이미지를 승격하고 항상 사용함으로써 한 환경에서 다른 환경으로 승격될 때
   서버의 불변성을 보장한다.



빌드 및 배포 프로세스는 네 가지 핵심 패턴을 기반으로 구축되었다.

- **지속적 통합/지속적 전달(CI/CD)**

  CI/CD를 사용하면 애플리케이션 코드가 커밋되면 코드가 빌드되고 테스트될 뿐만 아니라
  지속적으로 배포된다.
  코드 배포 과정은 코드가 단위,통합,플랫폼 테스트를 통과하면
  즉시 다음 환경으로 승격되도록 진행해야 한다.
  대부분의 조직에서 유일하게 멈출 시점은 운영 환경에 적용할 때다.

- **코드형 인프라스트럭처**

  개발 환경 및 다른 황경에 적용될 마지막 소프트웨어 산출물은 머신 이미지다.
  머신 이미지와 이미지에 설치된 마이크로서비스는 마이크로서비스 소스 코드를
  컴파일하고 테스트한 직후 프로비저닝된다.
  머신 이미지의 프로비저닝은 각 빌드와 함께 실행되는 일련의 스크립트를 통해 수행된다.
  서버가 구축된 후에는 수동으로 수정되어서는 안 된다.
  프로비저닝 스크립트는 소스 제어에 저장되어 일반 코드처럼 관리한다.

- **불변 서버**

​		서버 이미지가 생성되면 서버 구성과 마이크로서비스를 프로비저닝 프로세스 이후에 절대 변경할 수 없다.
​		이는 개발자나 시스템 관리자가 나중에 장애의 원인이 될 수 있는 '작은 변경'에 의해 '구성 편차'를
​		겪지 않도록 해 준다.
​		변경이 필요하면 서버 프로비저닝 스크립트를 변경하고 새 빌드를 시작해야 한다.



**불변성과 피닉스 서버의 부상**

불변 서버의 개념 덕분에 서버 구성이 서버의 머신 임미지가 가진 것과 정확히 일치한다는 것을 보장할 수 있다.
서버는 서비스나 마이크로서비스 동작을 변경하지 않고도 강제 종료하고
머신 이미지로 재시작할 수 있는 옵션이 있어야 한다.
마틴 파울러는 이러한 죽음과 새로운 서버의 부활을 피닉스 서버라고 명령했다.
피닉스 서버 패턴은 두 가지 이점이 있다.

1. 환경에서 구성 편차를 노출시키고 몰아낸다
   새로운 서버를 지속적으로 없애고 설정한다면 구성 편차가 일찍 드러나기 쉽고
   일관성을 보장하는 데 큰 효과가 있다.
2. 서버나 서비스를 종료하고 재시작한 후에도 완전히 복구할 수 없는 상황을 찾는 데 도움을 주면서
   회복력을 향상시킨다.
   마이크로서비스 아키텍처에서 서비스는 무상태가 되고 서버가 죽는 일은 일시적인 현상임을 기억해야 한다.
   서버를 무작위로 강제 종료하고 재시작하면 서비스나 인프라스트럭처에서 상태가 유지되는 상황이
   일찍 드러날 수 있다.



## 10.8 요약

- 빌드 및 배포 파이프라인은 마이크로서비스 제공을 위해 매우 중요한 부분이다.
  제대로 작동하는 빌드 및 배포 파이프라인을 통해 새로운 기능과 버그 수정을 몇 분 안에 배포할 수 있다.
- 빌드 및 배포 파이프라인은 서비스를 제공하는 데 사람의 직접적인 개입 없이 자동화되어야 한다.
  프로세스의 수동 부분은 변동 및 실패 가능성을 나타낸다.
- 빌드 및 배포 파이프라인의 자동화에는 많은 스크립팅과 올바른 구성이 필요하다.
  자동화 구축을 위해 필요한 일의 양을 과소평가해서는 안 된다.
- 빌드 및 배포 파이프라인은 불변 가상 머신 또는 컨테이너 이미지를 제공해야 한다.
  서버 이미지가 생성된 후에는 절대 변경되면 안 된다.
- 환경별 서버 구성은 서버가 설정될때 매개변수로 전달되어야 한다.